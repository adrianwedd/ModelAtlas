- id: 1
  title: "Scrape Hugging Face Models"
  description: "Initial scrape of Hugging Face Hub for model metadata using their API."
  component: "Scraper"
  dependencies: []
  priority: 1
  status: "done"
  command: "python tools/scrape_hf.py"
  execution:
    tool: "scrape_hf"
    args: {}
  task_id: "HF-001"
  area: "Data Ingestion"
  actionable_steps:
    - "Use Hugging Face Hub API to list and fetch model details."
    - "Store each model's data in models/huggingface/."
  acceptance_criteria:
    - "At least 100 models parsed and saved."
    - "No malformed JSON or missing name/version fields."
  assigned_to: "DataCurator"
  ci_notes: "⚙️ Optimized for API calls: ensure script handles rate limits, retries, and efficient data parsing."
  epic: "Data Acquisition"

- id: 1.1
  title: "Scrape Ollama.com Specific Data"
  description: "Scrape Ollama.com for data not available on Hugging Face Hub, including execution commands and detailed tag info via Registry API."
  component: "Scraper"
  dependencies: [1]
  priority: 1
  status: "done"
  command: "python tools/scrape_ollama.py"
  execution:
    tool: "scrape_ollama"
    args: {}
  task_id: "OLLAMA-001-WEB"
  area: "Data Ingestion"
  actionable_steps:
    - "Use Playwright to scrape Ollama.com for model details."
    - "Use Ollama Registry API to fetch detailed tag manifests."
    - "Store each model's data in models/ollama/."
  acceptance_criteria:
    - "All models from Ollama.com indexed."
    - "Detailed tag info (digest, size, context, input type) extracted."
    - "No malformed JSON or missing name/version fields."
  assigned_to: "DataCurator"
  ci_notes: "⚙️ Optimized for web scraping: ensure robust error handling, screenshots on failure, and console logging."
  epic: "Data Acquisition"

- id: 2
  title: "Enrich model metadata with LLM"
  description: "Use prompt engineering to generate model summaries, use cases, strengths, and potential limitations."
  component: "LLMEnricher"
  dependencies: [1]
  priority: 2
  status: "done"
  command: "python tools/enrich_metadata.py"
  execution:
    tool: "enrich_metadata"
    args:
      input: "data/models_raw.json"
      output: "data/models_enriched.json"
  task_id: "OLLAMA-002"
  area: "Semantic Enrichment"
  actionable_steps:
    - "Design prompts to extract developer-friendly model summaries"
    - "Include comparisons with similar models"
    - "Extract strengths and weaknesses heuristically"
  acceptance_criteria:
    - "Each model in models_enriched.json has summary, strengths, weaknesses, and use_cases"
    - "Generated content passes hallucination check"
  assigned_to: "LLMEnricher"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "Metadata Enrichment"

- id: 3
  title: "Normalize and validate enriched metadata"
  description: "Standardize license names, architecture types, and deduplicate tags across models."
  component: "DataCurator"
  dependencies: [2]
  priority: 2
  status: "done"
  command: "python tools/normalize_and_validate.py --input data/models_enriched.json --schema schemas/model.schema.json --output data/models_validated.json"
  execution:
    tool: "normalize_and_validate"
    args:
      input: "data/models_enriched.json"
      schema: "schemas/model.schema.json"
      output: "data/models_validated.json"
  task_id: "OLLAMA-003"
  area: "Data Quality"
  actionable_steps:
    - "Normalize 'MIT'/'mit'/'MIT License' → 'MIT'"
    - "Ensure every architecture_family uses consistent naming (e.g. 'transformer')"
    - "Strip whitespace and duplicates from tags"
  acceptance_criteria:
    - "All models validate against schema"
    - "No duplicate or conflicting licenses/architectures"
  assigned_to: "DataCurator"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "Data Cleaning"

- id: 4
  title: "Compute model similarity and populate `similar_models`"
  description: "Embed model summaries and use cosine similarity to find top-N nearest models."
  component: "SimilarityMapper"
  dependencies: [3]
  priority: 3
  status: "done"
  command: "python tools/similarity_mapper.py --input data/models_validated.json --output data/models_similar.json"
  execution:
    tool: "similarity_mapper"
    args:
      input: "data/models_validated.json"
      output: "data/models_similar.json"
  task_id: "OLLAMA-004"
  area: "Similarity Mapping"
  actionable_steps:
    - "Generate vector embeddings for summaries"
    - "Run pairwise similarity and threshold for closeness"
    - "Attach top 3 similar models to each model"
  acceptance_criteria:
    - "Each model has a similar_models field with 1-5 entries"
    - "Similarity scores stored or optionally visualized"
  assigned_to: "SimilarityMapper"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "Model Intelligence"

- id: 5
  title: "Generate visualizations for dashboard"
  description: "Produce model filter charts and comparative plots from normalized metadata."
  component: "VizArchitect"
  dependencies: [3]
  priority: 3
  status: "done"
  command: "python tools/gen_viz.py"
  execution:
    tool: "gen_viz"
    args: {}
  task_id: "OLLAMA-005"
  area: "Visualization"
  actionable_steps:
    - "Generate bar/pie charts for license, size distribution"
    - "Plot trust score vs downloads, trust vs params"
    - "Build mock dashboard with `recharts` or `matplotlib`"
  acceptance_criteria:
    - "Visuals exist as SVGs or embedded markdown"
    - "At least 3 plots are usable in README.md"
  assigned_to: "VizArchitect"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "UX + Output"

- id: 6
  title: "Synthesize enriched README.md"
  description: "Summarize the trace, provide model selection guidance, include visuals and stats."
  component: "ReadmeSynthesizer"
  dependencies: [4, 5]
  priority: 4
  status: "done"
  command: "python generate_readme.py --input data/models_similar.json --output README.md"
  execution:
    tool: "generate_readme"
    args:
      input: "data/models_similar.json"
      output: "README.md"
  task_id: "OLLAMA-006"
  area: "Documentation"
  actionable_steps:
    - "Write overview, usage, data trace explanation"
    - "Highlight top models with badges"
    - "Embed charts, model count, trust rankings"
  acceptance_criteria:
    - "README.md renders clearly and provides full trace overview"
    - "Includes >3 charts, top-10 table, and usage examples"
  assigned_to: "ReadmeSynthesizer"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "UX + Output"

- id: 7
  title: "Deploy API to serve model data"
  description: "Expose the enriched and validated model data via a simple REST API."
  component: "APIDeployer"
  dependencies: [4]
  priority: 4
  status: "done"
  command: "python tools/serve_api.py"
  execution:
    tool: "serve_api"
    args: {}
  task_id: "OLLAMA-007"
  area: "Backend"
  actionable_steps:
    - "Design simple GET endpoints for model info and similar models"
    - "Serve data from models_similar.json"
    - "Include basic filtering support via query parameters"
  acceptance_criteria:
    - "API serves JSON with valid structure"
    - "Endpoints return data within 200ms for local queries"
  assigned_to: "APIDeployer"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "API Layer"

- id: 8
  title: "Integrate with Ollama UI demo"
  description: "Feed enriched model info and similarity results into the interactive frontend."
  component: "UIDeveloper"
  dependencies: [5, 7]
  priority: 4
  status: "pending"
  command: null
  execution:
    tool: "integrate_ui"
    args: {}
  task_id: "OLLAMA-008"
  area: "Frontend"
  actionable_steps:
    - "Consume REST API and render model metadata"
    - "Add interactive filters and sorting options"
    - "Display model lineage or similarity links as graph"
  acceptance_criteria:
    - "UI shows complete model metadata"
    - "Similarity links render on hover or click"
  assigned_to: "UIDeveloper"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "UX + Output"

- id: 9
  title: "Agentify trace via LangGraph"
  description: "Break trace into LangGraph tasks executed by autonomous agents."
  component: "AgentOrchestrator"
  dependencies: [6, 7]
  priority: 5
  status: "pending"
  command: null
  execution:
    tool: "agentify_trace"
    args: {}
  task_id: "OLLAMA-009"
  area: "Automation"
  actionable_steps:
    - "Create nodes for scrape, enrich, validate, map, visualize"
    - "Integrate with LangGraph or custom orchestrator"
    - "Include memory passing and failure recovery"
  acceptance_criteria:
    - "Agents trigger sequentially or via event hooks"
    - "Error handling included per step"
  assigned_to: "AgentOrchestrator"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "Automation Layer"

- id: 10
  title: "Evaluate and rank models by trust and transparency"
  description: "Use risk heuristics and download metadata to rank models by transparency and reliability."
  component: "TrustRanker"
  dependencies: [3]
  priority: 3
  status: "pending"
  command: "python tools/rank_trust.py"
  execution:
    tool: "rank_trust"
    args: {}
  task_id: "OLLAMA-010"
  area: "Model Intelligence"
  actionable_steps:
    - "Parse download metrics"
    - "Apply transparency heuristics from RISK_HEURISTICS.md"
    - "Calculate composite trust scores"
  acceptance_criteria:
    - "Each model has a trust_score"
    - "Top-10 table appears in README"
  assigned_to: "TrustRanker"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "Metadata Enrichment"

- id: 11
  title: "Review Phase 1 Tasks for Completeness"
  description: "Conduct a structured audit of all completed Phase 1 tasks to ensure alignment with acceptance criteria and schema integrity."
  component: "QA"
  dependencies: [1, 1.1, 2, 3]
  priority: 2
  status: "pending"
  command: null
  execution:
    tool: "manual_review"
    args: {}
  task_id: "QA-001"
  area: "Quality Assurance"
  actionable_steps:
    - "Verify each completed task meets its acceptance criteria"
    - "Check all outputs validate against their respective schemas"
    - "Log any discrepancies and assign follow-up tasks"
  acceptance_criteria:
    - "Checklist completed for all completed Phase 1 tasks"
    - "No schema violations found in validated output"
  assigned_to: "QAReviewer"
  ci_notes: "🧪 Manual validation phase for upstream task correctness"
  epic: "Review & Validation"

- id: 12
  title: "Automated Schema Validation Regression Suite"
  description: "Execute a CI trace to validate all current and future model outputs against model.schema.json."
  component: "Validator"
  dependencies: [3]
  priority: 2
  status: "pending"
  command: "python tools/validate_all.py --input data/models_validated.json --schema schemas/model.schema.json"
  execution:
    tool: "validate_all"
    args:
      input: "data/models_validated.json"
      schema: "schemas/model.schema.json"
  task_id: "QA-002"
  area: "Quality Assurance"
  actionable_steps:
    - "Scan all model outputs and validate against schema"
    - "Print summary table of valid/invalid entries"
    - "Raise GitHub issue if schema violations are detected"
  acceptance_criteria:
    - "CI runs validation on all commits to main"
    - "100% of models conform to schema on success"
  assigned_to: "ValidatorBot"
  ci_notes: "🧪 Schema guardrail for metadata integrity"
  epic: "Review & Validation"
- id: 13
  title: "Integrate TrustForge in trace"
  description: "Remove hardcoded logic and wire TrustForge into enrich/main.py; update README and tasks.yml accordingly."
  component: "Trace"
  dependencies: [3]
  priority: 3
  status: "done"

- id: 14
  title: "Standardize RECURSOR naming"
  description: "Use a single term across docs and code (e.g., RECURSOR-1 vs RecursiveEnrichmentProcessor)."
  component: "Docs+Code"
  dependencies: []
  priority: 2
  status: "pending"

- id: 15
  title: "Implement end-to-end provenance tracing"
  description: "Extend tracepoint module so data can be followed from Ollama output to AtlasView."
  component: "Traceability"
  dependencies: [13]
  priority: 3
  status: "pending"

- id: 16
  title: "Create shared validation/serialization library"
  description: "Deduplicate logic from recursor and trustforge into a common module."
  component: "Core"
  dependencies: []
  priority: 3
  status: "pending"

- id: 17
  title: "Expand .gitignore"
  description: "Add typical Python ignores: __pycache__, *.pyc, *.egg-info, *.code-workspace, etc."
  component: "Repo"
  dependencies: []
  priority: 2
  status: "done"

- id: 18
  title: "Refactor atlas_cli using Typer or Click"
  description: "Break monolithic main.py into modular commands and subcommands."
  component: "CLI"
  dependencies: []
  priority: 3
  status: "in-progress"

- id: 19
  title: "Improve README Quick Start and diagrams"
  description: "Add concise setup instructions and regenerate visuals."
  component: "Docs"
  dependencies: []
  priority: 2
  status: "pending"

- id: 20
  title: "Ensure trailing newlines and add pre-commit check"
  description: "Fix missing newline endings in docs and enforce via pre-commit."
  component: "Repo"
  dependencies: []
  priority: 2
  status: "pending"

- id: 21
  title: "Refactor enrich/main.py into pluggable trace orchestrator"
  description: "Load stages from tasks.yml so recursor and trustforge can be swapped."
  component: "Trace"
  dependencies: [13, 16]
  priority: 4
  status: "pending"

- id: 22
  title: "Introduce test suite"
  description: "Set up pytest and add initial coverage for enrichment trace."
  component: "Testing"
  dependencies: []
  priority: 3
  status: "in-progress"

- id: 23
  title: "Create schemas/types.py for unified data schema"
  description: "Centralize all data structures and validation in schemas/."
  component: "Core"
  dependencies: [16]
  priority: 3
  status: "pending"

- id: 24
  title: "Implement Traceability mixin"
  description: "Allow recursor and trustforge to automatically log provenance metadata."
  component: "Traceability"
  dependencies: [15]
  priority: 3
  status: "pending"

- id: 25
  title: "Add pre-commit hooks"
  description: "Run black, isort, and generate_readme.py on each commit."
  component: "Repo"
  dependencies: [20]
  priority: 2
  status: "pending"

- id: 26
  title: "Agentic tasks.yml patcher"
  description: "Build GPT-4o agent to modify tasks.yml based on natural language requests."
  component: "Automation"
  dependencies: []
  priority: 4
  status: "pending"

- id: 27
  title: "Add --agent-mode to CLI"
  description: "Output structured JSON for easier chaining by agents."
  component: "CLI"
  dependencies: [18]
  priority: 3
  status: "pending"

- id: 28
  title: "Self-healing documentation action"
  description: "GitHub Action updates README/docs when code changes."
  component: "Automation"
  dependencies: [19]
  priority: 4
  status: "pending"

- id: 29
  title: "Cyberpunk CLI embellishments"
  description: "Use rich for styled output and a 'TRUTH FORGED' banner on completion."
  component: "CLI"
  dependencies: [18]
  priority: 3
  status: "pending"

- id: 30
  title: "Centralize text normalization"
  description: "Move duplicate normalize_text functions to common/text_utils.py and update imports."
  component: "Core"
  dependencies: []
  priority: 3
  status: "pending"

- id: 31
  title: "Terminology enforcement linter"
  description: "Create CONTRIBUTING lexicon and fail builds if docs or code use inconsistent terms."
  component: "Repo"
  dependencies: [25]
  priority: 3
  status: "pending"
- id: 32
  title: "TruthForge paradigm memo"
  description: "Outline the TruthForge paradigm shift and philosophy."
  component: "Docs"
  dependencies: []
  priority: 3
  status: "done"

- id: 33
  title: "Initialize Sphinx documentation site"
  description: "Initialize Sphinx docs site and integrate existing Markdown."
  component: "Docs"
  dependencies: []
  priority: 2
  status: "done"
- id: 101
  title: "Establish Single Source of Truth for Data Schemas"
  description: "Refactor the entire codebase to use a centralized set of Pydantic models for all data structures, eliminating hand-rolled dicts and making schema.md obsolete."
  component: "Core Architecture"
  dependencies: []
  priority: 1
  status: "done"
  area: "Refactor"
  actionable_steps:
    - "Created a new top-level `atlas_schemas` directory."
    - "Defined Pydantic models for `TraceableItem`, `Model`, and `TraceConfig`."
    - "Replaced dictionary manipulations in `enrich/main.py` and `trustforge/score.py` with Pydantic models."
    - "Removed the static `schema.md` file (if it existed)."
  acceptance_criteria:
    - "No module manually defines the shape of trace data."
    - "All data passed between `recursor` and `trustforge` is an instance of a Pydantic model from `atlas_schemas`."
  epic: "Foundational Hardening"
- id: 102
  title: "Unify Project Terminology"
  description: "Decide on and enforce a single, canonical term for a trace execution across the entire repository (code, docs, CLI)."
  component: "DX"
  dependencies: []
  priority: 1
  status: "pending"
  area: "Consistency"
  actionable_steps:
    - "Declare 'Trace' as the official term in a new `CONTRIBUTING.md` lexicon."
    - "Grep the codebase for 'job', 'run', 'workflow', 'pipeline' and replace with 'trace'."
    - "Update all user-facing strings in `atlas_cli`."
    - "Update all log messages."
    - "Update the README and all other documentation."
  acceptance_criteria:
    - "The term 'trace' no longer appears in the codebase outside of historical changelogs."
    - "The primary CLI command is `atlas trace ...`."
  epic: "Foundational Hardening"
- id: 201
  title: "Implement Centralized Configuration"
  description: "Refactor configuration management to use a single, unified `Config` object loaded from a `.env` file."
  component: "Core Architecture"
  dependencies: [101]
  priority: 2
  status: "done"
  area: "Refactor"
  actionable_steps:
    - "Created `atlas_schemas/config.py` with a Pydantic-based settings management class."
    - "Ensured it loads configuration from a `.env` file and has sane defaults."
    - "Refactored `enrich/main.py`, `trustforge/score.py`, `tools/scrape_hf.py`, `tools/scrape_ollama.py`, and `tools/enrich_metadata.py` to import and use this config object."
    - "Removed hardcoded paths and `os.environ` calls from these modules."
  acceptance_criteria:
    - "A single `.env.example` file exists at the project root."
    - "`config.json` and other ad-hoc config files are deleted."
  epic: "Foundational Hardening"
- id: 301
  title: "Create Master Integration Test"
  description: "Build a single, comprehensive integration test that runs the entire trace from a sample input file to a final output file."
  component: "Testing"
  dependencies: [101, 201]
  priority: 3
  status: "done"
  area: "Testing"
  actionable_steps:
    - "Created a `tests/integration` directory."
    - "Added `test_full_trace.py` with basic CLI invocation and output validation."
    - "Integrated `enrich/main.py` and `trustforge/score.py` logic into `atlas_cli/main.py`."
    - "The test now successfully executes a basic end-to-end trace."
  acceptance_criteria:
    - "Executing `pytest` executes a full, end-to-end trace of the system."
    - "The test is integrated into the CI trace."
  epic: "Reliability & CI"
- id: 401
  title: "Overhaul README.md for GODMODE Tier"
  description: "Rewrite the README to be world-class, inspiring, and immediately useful for new contributors and potential users."
  component: "Documentation"
  dependencies: [102]
  priority: 4
  status: "pending"
  area: "DX"
  actionable_steps:
    - "Add a project logo/banner and professional badges."
    - "Write a strong, benefit-oriented one-line description."
    - "Add a 'Get Started in 60 Seconds' section with copy-pasteable commands."
    - "Embed a diagram of the high-level architecture."
    - "Ensure tone is confident and visionary."
  acceptance_criteria:
    - "A new developer can understand the project's purpose and run it locally in under a minute from the README alone."
  epic: "Onboarding & Polish"

- id: 402
  title: "Add open-source license"
  description: "Introduce MIT LICENSE file and update README with licensing statement."
  component: "Repo"
  dependencies: []
  priority: 1
  status: "pending"
  area: "Governance"
  actionable_steps:
    - "Create LICENSE using MIT template"
    - "Mention license in README footer"
  acceptance_criteria:
    - "LICENSE file present"
    - "README references MIT license"
  task_id: "GOV-001"
  epic: "Foundational Hardening"

- id: 403
  title: "Revise README quick start"
  description: "Add concise setup commands and clarify existing components."
  component: "Docs"
  dependencies: []
  priority: 2
  status: "done"
  area: "DX"
  actionable_steps:
    - "Add installation snippet with `pip install -r requirements.txt` and `playwright install`"
    - "Mention which Python file runs the enrichment pipeline"
    - "Clarify location of CLI scripts"
  acceptance_criteria:
    - "New contributor can run scraper and enrichment in <1 minute"
    - "README passes markdown lint"
  task_id: "DOCS-001"
  epic: "Onboarding & Polish"

- id: 404
  title: "Synchronize CONTRIBUTING with codebase"
  description: "Update CONTRIBUTING.md to reference actual script names and remove nonexistent files."
  component: "Docs"
  dependencies: []
  priority: 2
  status: "done"
  area: "Consistency"
  actionable_steps:
    - "Replace references to scrape_models.py/enrich_models.py with tools/scrape_*.py and enrich/main.py"
    - "Remove CHANGELOG mention or create the file"
  acceptance_criteria:
    - "All script names in CONTRIBUTING.md exist in repo"
    - "Instructions mention running tests via pytest"
  task_id: "DOCS-002"
  epic: "Onboarding & Polish"

- id: 405
  title: "Introduce .editorconfig"
  description: "Add a basic .editorconfig enforcing UTF-8, newline at EOF, and 4-space indentation."
  component: "Repo"
  dependencies: []
  priority: 3
  status: "pending"
  area: "Consistency"
  actionable_steps:
    - "Create .editorconfig in repo root"
    - "Align with existing Python style (PEP8)"
    - "Document pre-commit hook idea in CONTRIBUTING"
  acceptance_criteria:
    - ".editorconfig committed"
    - "Editors pick up settings automatically"
  task_id: "REPO-001"
  epic: "Foundational Hardening"

- id: 406
  title: "Refactor CLI into package"
  description: "Move ollama_search_cli.py into atlas_cli/ package and prepare for Typer-based subcommands."
  component: "CLI"
  dependencies: []
  priority: 3
  status: "done"
  area: "Refactor"
  actionable_steps:
    - "Create atlas_cli/__init__.py and atlas_cli/main.py"
    - "Wrap existing search logic using Typer"
    - "Update README usage examples"
  acceptance_criteria:
    - "`python -m atlas_cli search llama` works"
    - "Unit test covers basic command"
  task_id: "CLI-001"
  epic: "DX Improvement"

- id: 407
  title: "Add CI workflow"
  description: "Run tests and doc build on each push via GitHub Actions."
  component: "CI"
  dependencies: [403]
  priority: 3
  status: "done"
  area: "Automation"
  actionable_steps:
    - "Create .github/workflows/ci.yml"
    - "Install dependencies, run `pytest` and `make -C docs html`"
  acceptance_criteria:
    - "CI passes on main branch"
    - "Failing tests block merge"
  task_id: "CI-001"
  epic: "Reliability & CI"

- id: 408
  title: "Unit tests for TrustForge and similarity engine"
  description: "Increase coverage by testing score calculation and similarity heuristics."
  component: "Testing"
  dependencies: []
  priority: 3
  status: "done"
  area: "Testing"
  actionable_steps:
    - "Write tests for compute_score() edge cases"
    - "Create tests for ModelSimilarityEngine.calculate_name_similarity()"
  acceptance_criteria:
    - "pytest shows >80% coverage for these modules"
  task_id: "TEST-001"
  epic: "Reliability & CI"

- id: 409
  title: "Create template directory for README generation"
  description: "Add templates/README.md.j2 and adjust generate_readme.py to use it."
  component: "Docs"
  dependencies: []
  priority: 2
  status: "done"
  area: "Automation"
  actionable_steps:
    - "Create templates/ directory with Jinja2 template"
    - "Ensure generate_readme.py succeeds via make target"
  acceptance_criteria:
    - "generate_readme.py generates README without error"
    - "Template documented in CONTRIBUTING"
  task_id: "DOCS-003"
  epic: "UX + Output"

- id: 410
  title: "Provide .env.example fields for all configurable keys"
  description: "Expand .env.example with placeholders for future API keys or settings."
  component: "Config"
  dependencies: []
  priority: 2
  status: "done"
  area: "Refactor"
  actionable_steps:
    - "Add PLAYWRIGHT_BROWSERS_PATH, OPENAI_API_KEY placeholders"
    - "Update README to refer to .env file"
  acceptance_criteria:
    - ".env.example contains at least three documented keys"
  task_id: "CONFIG-001"
  epic: "Foundational Hardening"

- id: 411
  title: "Implement pre-commit hooks"
  description: "Run black, isort, and trailing newline check before commits."
  component: "Repo"
  dependencies: [405]
  priority: 3
  status: "done"
  area: "Automation"
  actionable_steps:
    - "Add pre-commit configuration with black/isort"
    - "Document setup in CONTRIBUTING"
  acceptance_criteria:
    - "pre-commit passes locally and in CI"
  task_id: "REPO-002"
  epic: "Foundational Hardening"

- id: 412
  title: "Add Git LFS support"
  description: "Install Git LFS and track data directories."
  component: "Repo"
  dependencies: []
  priority: 2
  status: "done"
  area: "Automation"
  actionable_steps:
    - "Run `git lfs install` in repository"
    - "Track data/ and enriched_outputs/ via .gitattributes"
    - "Document setup in README"
  acceptance_criteria:
    - "Large artifacts stored via Git LFS"
    - "README explains how to install Git LFS"
  task_id: "REPO-003"
  epic: "Foundational Hardening"

- id: 413
  title: "Enable caching for scrapers"
  description: "Integrate requests-cache with CLI toggle and document cache path."
  component: "Scraper"
  dependencies: [1, 1.1]
  priority: 2
  status: "done"
  epic: "Data Acquisition"

- id: 414
  title: "Centralize logging configuration"
  description: "Create shared logging module with rotation and timestamps; update CLI and utilities to use it."
  component: "Core"
  dependencies: []
  priority: 2
  status: "done"
  epic: "Refactor"


- id: 415
  title: "Add lint workflow"
  description: "Create .github/workflows/lint.yml running black --check, isort --check, and flake8; integrate with CI."
  component: "CI"
  dependencies: [407]
  priority: 3
  status: "done"
  area: "Automation"
  actionable_steps:
    - "Create lint.yml"
    - "Have ci.yml depend on lint job"
  acceptance_criteria:
    - "CI fails on formatting violations"
  task_id: "CI-002"
  epic: "Reliability & CI"

- id: 416
  title: "Raise error on missing config keys"
  description: "Update atlas_schemas/config.py to raise a helpful error if required keys are missing."
  component: "Config"
  dependencies: [201]
  priority: 2
  status: "done"
  area: "Bugfix"
  actionable_steps:
    - "Add validation for required environment variables in Config"
    - "Write tests for missing key scenarios"
  acceptance_criteria:
    - "Config initialization fails with clear error when LLM_API_KEY is absent"
    - "tests/test_config.py passes"
  task_id: "CONFIG-002"
  epic: "Foundational Hardening"

- id: 417
  title: "Document LUMEN UX audit"
  description: "Save UX audit summary and redesign recommendations from LUMEN to docs/UX_AUDIT_LUMEN.md."
  component: "Docs"
  dependencies: []
  priority: 2
  status: "done"
  area: "UX Research"
  actionable_steps:
    - "Create docs/UX_AUDIT_LUMEN.md summarizing findings"
    - "Add corresponding tasks to tasks.yml"
  acceptance_criteria:
    - "File docs/UX_AUDIT_LUMEN.md exists with audit summary"
  epic: "Onboarding & Polish"

- id: 418
  title: "Clarify README components and dashboard note"
  description: "Add Components and Toolchain subheadings and mention that the dashboard code is not yet included."
  component: "Docs"
  dependencies: []
  priority: 3
  status: "pending"
  area: "DX"
  actionable_steps:
    - "Add \u1F4E6 Components and \u1F6E0 Toolchain headers"
    - "Explain missing dashboards/ directory or planned dashboard"
    - "Ensure quick start block remains clear"
  acceptance_criteria:
    - "README clarifies dashboard status and includes new headers"
  epic: "UX"

- id: 419
  title: "Improve CLI help and error messaging"
  description: "Group trace options in help text, show output examples, and provide guidance when tasks.yml is missing or after init."
  component: "CLI"
  dependencies: [18]
  priority: 3
  status: "pending"
  actionable_steps:
    - "Add 'Trace Options' heading in help output"
    - "Include input/output examples"
    - "Warn to run 'atlas init' if tasks.yml missing"
    - "Remind to add API keys after init"
  acceptance_criteria:
    - "CLI help shows grouped options and examples"
    - "Missing tasks.yml message guides the user"
  epic: "DX Improvement"

- id: 420
  title: "Document atlas search alias"
  description: "Clarify in README and CLI whether 'atlas search' is a subcommand or alias."
  component: "CLI"
  dependencies: [18]
  priority: 3
  status: "pending"
  actionable_steps:
    - "Expose search as official subcommand or document alias"
    - "Update README examples accordingly"
  acceptance_criteria:
    - "Users can run atlas search or know correct command"
  epic: "DX Improvement"

- id: 421
  title: "Unify CLI naming in docs"
  description: "Standardize use of 'atlas' vs 'atlas-cli' across documentation."
  component: "Docs"
  dependencies: []
  priority: 2
  status: "pending"
  actionable_steps:
    - "Audit docs for inconsistent CLI naming"
    - "Replace references to use a single term"
  acceptance_criteria:
    - "Documentation consistently refers to the CLI"
  epic: "Consistency"

- 1d: 422
  title: "Write CLI search tests"
  description: "Add unit tests for atlas_cli.search module"
  component: "Testing"
  dependencies: []
  priority: 2
  status: "done"
  area: "Testing"
  actionable_steps:
    - "Create atlas_cli/search.py with basic search logic"
    - "Write pytest tests covering query patterns"
  acceptance_criteria:
    - "pytest coverage shows >80% for atlas_cli/search.py"
  task_id: "CLI-TEST-001"
  epic: "Reliability & CI"
