- id: 1
  title: "Scrape Hugging Face Models"
  description: "Initial scrape of Hugging Face Hub for model metadata using their API."
  component: "Scraper"
  dependencies: []
  priority: 1
  status: "done"
  command: "python tools/scrape_hf.py"
  execution:
    tool: "scrape_hf"
    args: {}
  task_id: "HF-001"
  area: "Data Ingestion"
  actionable_steps:
    - "Use Hugging Face Hub API to list and fetch model details."
    - "Store each model's data in models/huggingface/."
  acceptance_criteria:
    - "At least 100 models parsed and saved."
    - "No malformed JSON or missing name/version fields."
  assigned_to: "DataCurator"
  ci_notes: "⚙️ Optimized for API calls: ensure script handles rate limits, retries, and efficient data parsing."
  epic: "Data Acquisition"

- id: 1.1
  title: "Scrape Ollama.com Specific Data"
  description: "Scrape Ollama.com for data not available on Hugging Face Hub, including run commands and detailed tag info via Registry API."
  component: "Scraper"
  dependencies: [1]
  priority: 1
  status: "done"
  command: "python tools/scrape_ollama.py"
  execution:
    tool: "scrape_ollama"
    args: {}
  task_id: "OLLAMA-001-WEB"
  area: "Data Ingestion"
  actionable_steps:
    - "Use Playwright to scrape Ollama.com for model details."
    - "Use Ollama Registry API to fetch detailed tag manifests."
    - "Store each model's data in models/ollama/."
  acceptance_criteria:
    - "All models from Ollama.com indexed."
    - "Detailed tag info (digest, size, context, input type) extracted."
    - "No malformed JSON or missing name/version fields."
  assigned_to: "DataCurator"
  ci_notes: "⚙️ Optimized for web scraping: ensure robust error handling, screenshots on failure, and console logging."
  epic: "Data Acquisition"

- id: 2
  title: "Enrich model metadata with LLM"
  description: "Use prompt engineering to generate model summaries, use cases, strengths, and potential limitations."
  component: "LLMEnricher"
  dependencies: [1]
  priority: 2
  status: "done"
  command: "python tools/enrich_metadata.py"
  execution:
    tool: "enrich_metadata"
    args:
      input: "data/models_raw.json"
      output: "data/models_enriched.json"
  task_id: "OLLAMA-002"
  area: "Semantic Enrichment"
  actionable_steps:
    - "Design prompts to extract developer-friendly model summaries"
    - "Include comparisons with similar models"
    - "Extract strengths and weaknesses heuristically"
  acceptance_criteria:
    - "Each model in models_enriched.json has summary, strengths, weaknesses, and use_cases"
    - "Generated content passes hallucination check"
  assigned_to: "LLMEnricher"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "Metadata Enrichment"

- id: 3
  title: "Normalize and validate enriched metadata"
  description: "Standardize license names, architecture types, and deduplicate tags across models."
  component: "DataCurator"
  dependencies: [2]
  priority: 2
  status: "done"
  command: "python tools/normalize_and_validate.py --input data/models_enriched.json --schema schemas/model.schema.json --output data/models_validated.json"
  execution:
    tool: "normalize_and_validate"
    args:
      input: "data/models_enriched.json"
      schema: "schemas/model.schema.json"
      output: "data/models_validated.json"
  task_id: "OLLAMA-003"
  area: "Data Quality"
  actionable_steps:
    - "Normalize 'MIT'/'mit'/'MIT License' → 'MIT'"
    - "Ensure every architecture_family uses consistent naming (e.g. 'transformer')"
    - "Strip whitespace and duplicates from tags"
  acceptance_criteria:
    - "All models validate against schema"
    - "No duplicate or conflicting licenses/architectures"
  assigned_to: "DataCurator"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "Data Cleaning"

- id: 4
  title: "Compute model similarity and populate `similar_models`"
  description: "Embed model summaries and use cosine similarity to find top-N nearest models."
  component: "SimilarityMapper"
  dependencies: [3]
  priority: 3
  status: "pending"
  command: "python tools/similarity_mapper.py --input data/models_validated.json --output data/models_similar.json"
  execution:
    tool: "similarity_mapper"
    args:
      input: "data/models_validated.json"
      output: "data/models_similar.json"
  task_id: "OLLAMA-004"
  area: "Similarity Mapping"
  actionable_steps:
    - "Generate vector embeddings for summaries"
    - "Run pairwise similarity and threshold for closeness"
    - "Attach top 3 similar models to each model"
  acceptance_criteria:
    - "Each model has a similar_models field with 1-5 entries"
    - "Similarity scores stored or optionally visualized"
  assigned_to: "SimilarityMapper"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "Model Intelligence"

- id: 5
  title: "Generate visualizations for dashboard"
  description: "Produce model filter charts and comparative plots from normalized metadata."
  component: "VizArchitect"
  dependencies: [3]
  priority: 3
  status: "pending"
  command: "python tools/gen_viz.py"
  execution:
    tool: "gen_viz"
    args: {}
  task_id: "OLLAMA-005"
  area: "Visualization"
  actionable_steps:
    - "Generate bar/pie charts for license, size distribution"
    - "Plot trust score vs downloads, trust vs params"
    - "Build mock dashboard with `recharts` or `matplotlib`"
  acceptance_criteria:
    - "Visuals exist as SVGs or embedded markdown"
    - "At least 3 plots are usable in README.md"
  assigned_to: "VizArchitect"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "UX + Output"

- id: 6
  title: "Synthesize enriched README.md"
  description: "Summarize the pipeline, provide model selection guidance, include visuals and stats."
  component: "ReadmeSynthesizer"
  dependencies: [4, 5]
  priority: 4
  status: "pending"
  command: "python generate_readme.py --input data/models_similar.json --output README.md"
  execution:
    tool: "generate_readme"
    args:
      input: "data/models_similar.json"
      output: "README.md"
  task_id: "OLLAMA-006"
  area: "Documentation"
  actionable_steps:
    - "Write overview, usage, data pipeline explanation"
    - "Highlight top models with badges"
    - "Embed charts, model count, trust rankings"
  acceptance_criteria:
    - "README.md renders clearly and provides full pipeline overview"
    - "Includes >3 charts, top-10 table, and usage examples"
  assigned_to: "ReadmeSynthesizer"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "UX + Output"

- id: 7
  title: "Deploy API to serve model data"
  description: "Expose the enriched and validated model data via a simple REST API."
  component: "APIDeployer"
  dependencies: [4]
  priority: 4
  status: "pending"
  command: "python tools/serve_api.py"
  execution:
    tool: "serve_api"
    args: {}
  task_id: "OLLAMA-007"
  area: "Backend"
  actionable_steps:
    - "Design simple GET endpoints for model info and similar models"
    - "Serve data from models_similar.json"
    - "Include basic filtering support via query parameters"
  acceptance_criteria:
    - "API serves JSON with valid structure"
    - "Endpoints return data within 200ms for local queries"
  assigned_to: "APIDeployer"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "API Layer"

- id: 8
  title: "Integrate with Ollama UI demo"
  description: "Feed enriched model info and similarity results into the interactive frontend."
  component: "UIDeveloper"
  dependencies: [5, 7]
  priority: 4
  status: "pending"
  command: null
  execution:
    tool: "integrate_ui"
    args: {}
  task_id: "OLLAMA-008"
  area: "Frontend"
  actionable_steps:
    - "Consume REST API and render model metadata"
    - "Add interactive filters and sorting options"
    - "Display model lineage or similarity links as graph"
  acceptance_criteria:
    - "UI shows complete model metadata"
    - "Similarity links render on hover or click"
  assigned_to: "UIDeveloper"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "UX + Output"

- id: 9
  title: "Agentify pipeline via LangGraph"
  description: "Break pipeline into LangGraph tasks executed by autonomous agents."
  component: "AgentOrchestrator"
  dependencies: [6, 7]
  priority: 5
  status: "pending"
  command: null
  execution:
    tool: "agentify_pipeline"
    args: {}
  task_id: "OLLAMA-009"
  area: "Automation"
  actionable_steps:
    - "Create nodes for scrape, enrich, validate, map, visualize"
    - "Integrate with LangGraph or custom orchestrator"
    - "Include memory passing and failure recovery"
  acceptance_criteria:
    - "Agents trigger sequentially or via event hooks"
    - "Error handling included per step"
  assigned_to: "AgentOrchestrator"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "Automation Layer"

- id: 10
  title: "Evaluate and rank models by trust and transparency"
  description: "Use risk heuristics and download metadata to rank models by transparency and reliability."
  component: "TrustRanker"
  dependencies: [3]
  priority: 3
  status: "pending"
  command: "python tools/rank_trust.py"
  execution:
    tool: "rank_trust"
    args: {}
  task_id: "OLLAMA-010"
  area: "Model Intelligence"
  actionable_steps:
    - "Parse download metrics"
    - "Apply transparency heuristics from RISK_HEURISTICS.md"
    - "Calculate composite trust scores"
  acceptance_criteria:
    - "Each model has a trust_score"
    - "Top-10 table appears in README"
  assigned_to: "TrustRanker"
  ci_notes: "⚙️ Optimized for GitHub Actions: ensure script runtime < 6 mins, use minimal dependencies, write to /tmp or workspace only."
  epic: "Metadata Enrichment"

- id: 11
  title: "Review Phase 1 Tasks for Completeness"
  description: "Conduct a structured audit of all completed Phase 1 tasks to ensure alignment with acceptance criteria and schema integrity."
  component: "QA"
  dependencies: [1, 1.1, 2, 3]
  priority: 2
  status: "pending"
  command: null
  execution:
    tool: "manual_review"
    args: {}
  task_id: "QA-001"
  area: "Quality Assurance"
  actionable_steps:
    - "Verify each completed task meets its acceptance criteria"
    - "Check all outputs validate against their respective schemas"
    - "Log any discrepancies and assign follow-up tasks"
  acceptance_criteria:
    - "Checklist completed for all completed Phase 1 tasks"
    - "No schema violations found in validated output"
  assigned_to: "QAReviewer"
  ci_notes: "🧪 Manual validation phase for upstream task correctness"
  epic: "Review & Validation"

- id: 12
  title: "Automated Schema Validation Regression Suite"
  description: "Run a CI job to validate all current and future model outputs against model.schema.json."
  component: "Validator"
  dependencies: [3]
  priority: 2
  status: "pending"
  command: "python tools/validate_all.py --input data/models_validated.json --schema schemas/model.schema.json"
  execution:
    tool: "validate_all"
    args:
      input: "data/models_validated.json"
      schema: "schemas/model.schema.json"
  task_id: "QA-002"
  area: "Quality Assurance"
  actionable_steps:
    - "Scan all model outputs and validate against schema"
    - "Print summary table of valid/invalid entries"
    - "Raise GitHub issue if schema violations are detected"
  acceptance_criteria:
    - "CI runs validation on all commits to main"
    - "100% of models conform to schema on success"
  assigned_to: "ValidatorBot"
  ci_notes: "🧪 Schema guardrail for metadata integrity"
  epic: "Review & Validation"
- id: 13
  title: "Integrate TrustForge in pipeline"
  description: "Remove hardcoded logic and wire TrustForge into enrich/main.py; update README and tasks.yml accordingly."
  component: "Pipeline"
  dependencies: [3]
  priority: 3
  status: "done"

- id: 14
  title: "Standardize RECURSOR naming"
  description: "Use a single term across docs and code (e.g., RECURSOR-1 vs RecursiveEnrichmentProcessor)."
  component: "Docs+Code"
  dependencies: []
  priority: 2
  status: "pending"

- id: 15
  title: "Implement end-to-end provenance tracing"
  description: "Extend tracepoint module so data can be followed from Ollama output to AtlasView."
  component: "Traceability"
  dependencies: [13]
  priority: 3
  status: "pending"

- id: 16
  title: "Create shared validation/serialization library"
  description: "Deduplicate logic from recursor and trustforge into a common module."
  component: "Core"
  dependencies: []
  priority: 3
  status: "pending"

- id: 17
  title: "Expand .gitignore"
  description: "Add typical Python ignores: __pycache__, *.pyc, *.egg-info, *.code-workspace, etc."
  component: "Repo"
  dependencies: []
  priority: 2
  status: "done"

- id: 18
  title: "Refactor atlas_cli using Typer or Click"
  description: "Break monolithic main.py into modular commands and subcommands."
  component: "CLI"
  dependencies: []
  priority: 3
  status: "pending"

- id: 19
  title: "Improve README Quick Start and diagrams"
  description: "Add concise setup instructions and regenerate visuals."
  component: "Docs"
  dependencies: []
  priority: 2
  status: "pending"

- id: 20
  title: "Ensure trailing newlines and add pre-commit check"
  description: "Fix missing newline endings in docs and enforce via pre-commit."
  component: "Repo"
  dependencies: []
  priority: 2
  status: "pending"

- id: 21
  title: "Refactor enrich/main.py into pluggable pipeline orchestrator"
  description: "Load stages from tasks.yml so recursor and trustforge can be swapped."
  component: "Pipeline"
  dependencies: [13, 16]
  priority: 4
  status: "pending"

- id: 22
  title: "Introduce test suite"
  description: "Set up pytest and add initial coverage for enrichment pipeline."
  component: "Testing"
  dependencies: []
  priority: 3
  status: "in-progress"

- id: 23
  title: "Create schemas/types.py for unified data schema"
  description: "Centralize all data structures and validation in schemas/."
  component: "Core"
  dependencies: [16]
  priority: 3
  status: "pending"

- id: 24
  title: "Implement Traceability mixin"
  description: "Allow recursor and trustforge to automatically log provenance metadata."
  component: "Traceability"
  dependencies: [15]
  priority: 3
  status: "pending"

- id: 25
  title: "Add pre-commit hooks"
  description: "Run black, isort, and generate_readme.py on each commit."
  component: "Repo"
  dependencies: [20]
  priority: 2
  status: "pending"

- id: 26
  title: "Agentic tasks.yml patcher"
  description: "Build GPT-4o agent to modify tasks.yml based on natural language requests."
  component: "Automation"
  dependencies: []
  priority: 4
  status: "pending"

- id: 27
  title: "Add --agent-mode to CLI"
  description: "Output structured JSON for easier chaining by agents."
  component: "CLI"
  dependencies: [18]
  priority: 3
  status: "pending"

- id: 28
  title: "Self-healing documentation action"
  description: "GitHub Action updates README/docs when code changes."
  component: "Automation"
  dependencies: [19]
  priority: 4
  status: "pending"

- id: 29
  title: "Cyberpunk CLI embellishments"
  description: "Use rich for styled output and a 'TRUTH FORGED' banner on completion."
  component: "CLI"
  dependencies: [18]
  priority: 3
  status: "pending"

- id: 30
  title: "Centralize text normalization"
  description: "Move duplicate normalize_text functions to common/text_utils.py and update imports."
  component: "Core"
  dependencies: []
  priority: 3
  status: "pending"

- id: 31
  title: "Terminology enforcement linter"
  description: "Create CONTRIBUTING lexicon and fail builds if docs or code use inconsistent terms."
  component: "Repo"
  dependencies: [25]
  priority: 3
  status: "pending"
- id: 32
  title: "TruthForge paradigm memo"
  description: "Outline the TruthForge paradigm shift and philosophy."
  component: "Docs"
  dependencies: []
  priority: 3
  status: "done"

- id: 33
  title: "Initialize Sphinx documentation site"
  description: "Initialize Sphinx docs site and integrate existing Markdown."
  component: "Docs"
  dependencies: []
  priority: 2
  status: "done"
- id: 101
  title: "Establish Single Source of Truth for Data Schemas"
  description: "Refactor the entire codebase to use a centralized set of Pydantic models for all data structures, eliminating hand-rolled dicts and making schema.md obsolete."
  component: "Core Architecture"
  dependencies: []
  priority: 1
  status: "pending"
  area: "Refactor"
  actionable_steps:
    - "Create a new top-level `atlas_schemas` directory."
    - "Define Pydantic models for `TraceableItem`, `PipelineConfig`, and all other core types."
    - "Replace all dictionary manipulations in `recursor`, `trustforge`, and `atlas_cli` with these models."
    - "Remove the static `schema.md` file."
  acceptance_criteria:
    - "No module manually defines the shape of pipeline data."
    - "All data passed between `recursor` and `trustforge` is an instance of a Pydantic model from `atlas_schemas`."
  epic: "Foundational Hardening"
- id: 102
  title: "Unify Project Terminology"
  description: "Decide on and enforce a single, canonical term for a pipeline execution across the entire repository (code, docs, CLI)."
  component: "DX"
  dependencies: []
  priority: 1
  status: "pending"
  area: "Consistency"
  actionable_steps:
    - "Declare 'Trace' as the official term in a new `CONTRIBUTING.md` lexicon."
    - "Grep the codebase for 'job', 'run', 'workflow', 'pipeline' and replace with 'trace'."
    - "Update all user-facing strings in `atlas_cli`."
    - "Update all log messages."
    - "Update the README and all other documentation."
  acceptance_criteria:
    - "The term 'job' no longer appears in the codebase outside of historical changelogs."
    - "The primary CLI command is `atlas trace ...`."
  epic: "Foundational Hardening"
- id: 201
  title: "Implement Centralized Configuration"
  description: "Refactor configuration management to use a single, unified `Config` object loaded from a `.env` file."
  component: "Core Architecture"
  dependencies: [101]
  priority: 2
  status: "pending"
  area: "Refactor"
  actionable_steps:
    - "Create `atlas_schemas/config.py` with a Pydantic-based settings management class."
    - "Ensure it loads configuration from a `.env` file and has sane defaults."
    - "Refactor all modules to import and use this config object."
    - "Remove all other configuration files and `os.environ` calls."
  acceptance_criteria:
    - "A single `.env.example` file exists at the project root."
    - "`config.json` and other ad-hoc config files are deleted."
  epic: "Foundational Hardening"
- id: 301
  title: "Create Master Integration Test"
  description: "Build a single, comprehensive integration test that runs the entire pipeline from a sample input file to a final output file."
  component: "Testing"
  dependencies: [101, 201]
  priority: 3
  status: "pending"
  area: "Testing"
  actionable_steps:
    - "Create a `tests/integration` directory."
    - "Add `test_full_trace.py`."
    - "Create fixture data (`sample_input.jsonl`) and a fixture `tasks.yml`."
    - "The test should invoke the `atlas_cli` as a subprocess or library call and run a full trace."
    - "Assert that the output file is created and its content is valid."
  acceptance_criteria:
    - "Running `pytest` executes a full, end-to-end trace of the system."
    - "The test is integrated into the CI pipeline."
  epic: "Reliability & CI"
- id: 401
  title: "Overhaul README.md for GODMODE Tier"
  description: "Rewrite the README to be world-class, inspiring, and immediately useful for new contributors and potential users."
  component: "Documentation"
  dependencies: [102]
  priority: 4
  status: "pending"
  area: "DX"
  actionable_steps:
    - "Add a project logo/banner and professional badges."
    - "Write a strong, benefit-oriented one-line description."
    - "Add a 'Get Started in 60 Seconds' section with copy-pasteable commands."
    - "Embed a diagram of the high-level architecture."
    - "Ensure tone is confident and visionary."
  acceptance_criteria:
    - "A new developer can understand the project's purpose and run it locally in under a minute from the README alone."
  epic: "Onboarding & Polish