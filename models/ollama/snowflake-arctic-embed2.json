{
  "name": "snowflake-arctic-embed2",
  "description": "Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual support without sacrificing English performance or scalability.",
  "license": "",
  "pull_count": 100000,
  "last_updated": "Dec 4, 2024 11:57 PM UTC",
  "readme_html": "<div class=\"prose-td code:display-inline-block prose-td code:bg-gray-200 prose-td code:px-2 prose-td code:py-1 prose-td code:rounded-md prose prose-headings:mb-[0.7em] prose-headings:mt-[1.25em] prose-headings:font-semibold prose-headings:tracking-tight prose-h1:text-[32px] prose-h2:text-2xl prose-h3:text-xl prose-h4:text-lg prose-h5:text-base prose-p:mb-4 prose-p:mt-0 prose-p:leading-relaxed prose-p:before:hidden prose-p:after:hidden prose-blockquote:font-normal prose-blockquote:not-italic prose-blockquote:text-neutral-500 prose-blockquote:before:hidden prose-blockquote:after:hidden prose-code:my-0 prose-code:inline-block prose-code:rounded-md prose-code:bg-neutral-100 prose-code:px-2 prose-code:text-[85%] prose-code:font-normal prose-code:leading-relaxed prose-code:text-black prose-code:before:hidden prose-code:after:hidden prose-pre:mb-4 prose-pre:mt-0 prose-pre:whitespace-pre-wrap prose-pre:rounded-lg prose-pre:bg-neutral-100 prose-pre:px-3 prose-pre:py-3 prose-pre:text-base prose-pre:text-black prose-ol:mb-4 prose-ol:mt-1 prose-ol:pl-8 marker:prose-ol:text-black prose-ul:mb-4 prose-ul:mt-1 prose-ul:pl-8 marker:prose-ul:text-black prose-li:mb-0 prose-li:mt-0.5 prose-li:text-black first:prose-li:mt-0 prose-table:w-full prose-table:table-auto prose-table:border-collapse prose-th:break-words prose-th:text-center prose-th:font-semibold prose-td:break-words prose-td:px-4 prose-td:py-2 prose-td:text-left prose-img:mx-auto prose-img:my-12 prose-video:my-12 max-w-none overflow-auto py-5 text-black\" id=\"display\">\n<p>Snowflake is excited to announce the release of Arctic Embed 2.0, the next iteration of our frontier embedding models, which now empower multilingual search. While our previous releases have been well received by our customers, partners and the open source community, leading to millions of downloads, we have consistently received one request: Can you make this model multilingual? Arctic Embed 2.0 builds on the robust foundation of our previous releases, adding multilingual support without sacrificing English performance or scalability, to address the needs of an even broader user base that spans a wide range of languages and applications.</p>\n<p><img alt=\"Snowflake data\" src=\"/assets/library/snowflake-arctic-embed2/0546501b-9897-4145-af38-1b352fafb89c\"/>\nFigure 1. Single-vector dense retrieval performance of open source multilingual embedding models with fewer than 1B parameters. Scores are average nDCG@10 on MTEB Retrieval and the subset of CLEF (ELRA, 2006) covering English, French, Spanish, Italian and German.</p>\n<h3>The diverse and powerful feature set of Arctic Embed 2.0</h3>\n<ol>\n<li><strong>Enterprise-ready throughput and efficiency:</strong> The Arctic Embed 2.0 models are built for large-scale enterprise demands. Even our \u201clarge\u201d model weighs in well under 1B parameters and delivers fast, high-throughput embedding capabilities. Based on internal testing, it easily handles more than 100 documents per second (on average) on NVIDIA A10 GPUs and achieves sub-10ms query embedding latency, enabling practical deployment on budget-friendly hardware.</li>\n<li><strong>Uncompromising quality for English and non-English retrieval:</strong> Despite their compact sizes, both Arctic Embed 2.0 models achieve impressive NDCG@10 scores across a variety of English and non-English benchmark data sets, demonstrating a capability to generalize well even to languages not included in the training recipe. These impressive benchmark scores position Arctic Embed 2.0 as a leader among frontier retrieval models.</li>\n<li><strong>Enabling scalable retrieval through Matryoshka Representation Learning (MRL):</strong> The Arctic Embed 2.0 release includes the same quantization-friendly MRL functionality introduced in Arctic Embed 1.5, allowing users to reduce cost and optimize scale when performing searches over large data sets. With both model sizes, users can achieve high-quality retrieval with as few as 128 bytes per vector (96x smaller than uncompressed embeddings from OpenAI\u2019s popular text-embedding-3-large model1). Just like Arctic Embed 1.5, the Arctic Embed 2.0 models also outshine several MRL-supporting peers with substantially lower quality degradation and higher benchmark scores in the compressed regime.</li>\n<li><strong>Truly open source:</strong> The Arctic Embed 2.0 models are released under the permissive Apache 2.0 license.</li>\n</ol>\n</div>",
  "page_hash": "ba0f23bed648",
  "readme_text": "\nSnowflake is excited to announce the release of Arctic Embed 2.0, the next iteration of our frontier embedding models, which now empower multilingual search. While our previous releases have been well received by our customers, partners and the open source community, leading to millions of downloads, we have consistently received one request: Can you make this model multilingual? Arctic Embed 2.0 builds on the robust foundation of our previous releases, adding multilingual support without sacrificing English performance or scalability, to address the needs of an even broader user base that spans a wide range of languages and applications.\n\nFigure 1. Single-vector dense retrieval performance of open source multilingual embedding models with fewer than 1B parameters. Scores are average nDCG@10 on MTEB Retrieval and the subset of CLEF (ELRA, 2006) covering English, French, Spanish, Italian and German.\nThe diverse and powerful feature set of Arctic Embed 2.0\n\nEnterprise-ready throughput and efficiency: The Arctic Embed 2.0 models are built for large-scale enterprise demands. Even our \u201clarge\u201d model weighs in well under 1B parameters and delivers fast, high-throughput embedding capabilities. Based on internal testing, it easily handles more than 100 documents per second (on average) on NVIDIA A10 GPUs and achieves sub-10ms query embedding latency, enabling practical deployment on budget-friendly hardware.\nUncompromising quality for English and non-English retrieval: Despite their compact sizes, both Arctic Embed 2.0 models achieve impressive NDCG@10 scores across a variety of English and non-English benchmark data sets, demonstrating a capability to generalize well even to languages not included in the training recipe. These impressive benchmark scores position Arctic Embed 2.0 as a leader among frontier retrieval models.\nEnabling scalable retrieval through Matryoshka Representation Learning (MRL): The Arctic Embed 2.0 release includes the same quantization-friendly MRL functionality introduced in Arctic Embed 1.5, allowing users to reduce cost and optimize scale when performing searches over large data sets. With both model sizes, users can achieve high-quality retrieval with as few as 128 bytes per vector (96x smaller than uncompressed embeddings from OpenAI\u2019s popular text-embedding-3-large model1). Just like Arctic Embed 1.5, the Arctic Embed 2.0 models also outshine several MRL-supporting peers with substantially lower quality degradation and higher benchmark scores in the compressed regime.\nTruly open source: The Arctic Embed 2.0 models are released under the permissive Apache 2.0 license.\n\n",
  "tags": [
    {
      "tag": "snowflake-arctic-embed2:latest",
      "last_updated": "7 months ago",
      "size": "1.2GB",
      "digest": "sha256:959bce8be13578b0ecfad6b4780f1eae5814f21ac5790dc9a3ad9f261cc8cb07",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:959bce8be13578b0ecfad6b4780f1eae5814f21ac5790dc9a3ad9f261cc8cb07",
          "size": 337
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:8c625c9569c3c799f5f9595b5a141f91d224233055608189d66746347c14e613",
            "size": 1160285024,
            "from": "/Users/administrator/.ollama/models/blobs/sha256-8c625c9569c3c799f5f9595b5a141f91d224233055608189d66746347c14e613"
          },
          {
            "mediaType": "Template",
            "digest": "sha256:58d1e17ffe5109a7ae296caafcadfdbe6a7d176f0bc4ab01e12a689b0499d8bd",
            "size": 11357
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "bert",
        "model_families": [
          "bert"
        ],
        "model_type": "566.70M",
        "file_type": "F16",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:8c625c9569c3c799f5f9595b5a141f91d224233055608189d66746347c14e613",
            "sha256:58d1e17ffe5109a7ae296caafcadfdbe6a7d176f0bc4ab01e12a689b0499d8bd"
          ]
        }
      },
      "context_length": null,
      "model_type": "566.70M",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "snowflake-arctic-embed2:568m",
      "last_updated": "7 months ago",
      "size": "1.2GB",
      "digest": "sha256:959bce8be13578b0ecfad6b4780f1eae5814f21ac5790dc9a3ad9f261cc8cb07",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:959bce8be13578b0ecfad6b4780f1eae5814f21ac5790dc9a3ad9f261cc8cb07",
          "size": 337
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:8c625c9569c3c799f5f9595b5a141f91d224233055608189d66746347c14e613",
            "size": 1160285024,
            "from": "/Users/administrator/.ollama/models/blobs/sha256-8c625c9569c3c799f5f9595b5a141f91d224233055608189d66746347c14e613"
          },
          {
            "mediaType": "Template",
            "digest": "sha256:58d1e17ffe5109a7ae296caafcadfdbe6a7d176f0bc4ab01e12a689b0499d8bd",
            "size": 11357
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "bert",
        "model_families": [
          "bert"
        ],
        "model_type": "566.70M",
        "file_type": "F16",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:8c625c9569c3c799f5f9595b5a141f91d224233055608189d66746347c14e613",
            "sha256:58d1e17ffe5109a7ae296caafcadfdbe6a7d176f0bc4ab01e12a689b0499d8bd"
          ]
        }
      },
      "context_length": null,
      "model_type": "566.70M",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "snowflake-arctic-embed2:568m-l-fp16",
      "last_updated": "7 months ago",
      "size": "1.2GB",
      "digest": "sha256:959bce8be13578b0ecfad6b4780f1eae5814f21ac5790dc9a3ad9f261cc8cb07",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:959bce8be13578b0ecfad6b4780f1eae5814f21ac5790dc9a3ad9f261cc8cb07",
          "size": 337
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:8c625c9569c3c799f5f9595b5a141f91d224233055608189d66746347c14e613",
            "size": 1160285024,
            "from": "/Users/administrator/.ollama/models/blobs/sha256-8c625c9569c3c799f5f9595b5a141f91d224233055608189d66746347c14e613"
          },
          {
            "mediaType": "Template",
            "digest": "sha256:58d1e17ffe5109a7ae296caafcadfdbe6a7d176f0bc4ab01e12a689b0499d8bd",
            "size": 11357
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "bert",
        "model_families": [
          "bert"
        ],
        "model_type": "566.70M",
        "file_type": "F16",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:8c625c9569c3c799f5f9595b5a141f91d224233055608189d66746347c14e613",
            "sha256:58d1e17ffe5109a7ae296caafcadfdbe6a7d176f0bc4ab01e12a689b0499d8bd"
          ]
        }
      },
      "context_length": null,
      "model_type": "566.70M",
      "quantization": null,
      "base_model": null
    }
  ],
  "annotations": {
    "ollama.input_type": "text"
  },
  "quality_score": {
    "fields_filled": 9,
    "total_possible": 15,
    "completeness": 0.6
  }
}