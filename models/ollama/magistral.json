{
  "name": "magistral",
  "description": "Magistral is a small, efficient reasoning model with 24B parameters.",
  "license": "Magistral is ideal for general purpose use requiring longer thought processing and better accuracy than with non-reasoning LLMs. From legal research and financial forecasting to software development and creative storytelling \u2014 this model solves multi-step challenges where transparency and precision are critical.",
  "pull_count": 173500,
  "last_updated": "Jun 16, 2025 8:46 PM UTC",
  "readme_html": "<div class=\"prose-td code:display-inline-block prose-td code:bg-gray-200 prose-td code:px-2 prose-td code:py-1 prose-td code:rounded-md prose prose-headings:mb-[0.7em] prose-headings:mt-[1.25em] prose-headings:font-semibold prose-headings:tracking-tight prose-h1:text-[32px] prose-h2:text-2xl prose-h3:text-xl prose-h4:text-lg prose-h5:text-base prose-p:mb-4 prose-p:mt-0 prose-p:leading-relaxed prose-p:before:hidden prose-p:after:hidden prose-blockquote:font-normal prose-blockquote:not-italic prose-blockquote:text-neutral-500 prose-blockquote:before:hidden prose-blockquote:after:hidden prose-code:my-0 prose-code:inline-block prose-code:rounded-md prose-code:bg-neutral-100 prose-code:px-2 prose-code:text-[85%] prose-code:font-normal prose-code:leading-relaxed prose-code:text-black prose-code:before:hidden prose-code:after:hidden prose-pre:mb-4 prose-pre:mt-0 prose-pre:whitespace-pre-wrap prose-pre:rounded-lg prose-pre:bg-neutral-100 prose-pre:px-3 prose-pre:py-3 prose-pre:text-base prose-pre:text-black prose-ol:mb-4 prose-ol:mt-1 prose-ol:pl-8 marker:prose-ol:text-black prose-ul:mb-4 prose-ul:mt-1 prose-ul:pl-8 marker:prose-ul:text-black prose-li:mb-0 prose-li:mt-0.5 prose-li:text-black first:prose-li:mt-0 prose-table:w-full prose-table:table-auto prose-table:border-collapse prose-th:break-words prose-th:text-center prose-th:font-semibold prose-td:break-words prose-td:px-4 prose-td:py-2 prose-td:text-left prose-img:mx-auto prose-img:my-12 prose-video:my-12 max-w-none overflow-auto py-5 text-black\" id=\"display\">\n<p><img src=\"/assets/library/mistral-small3.1/88f81c26-7028-4f08-b906-92b873d5536e\" width=\"120\"/></p>\n<p>Magistral is the first reasoning model by Mistral AI, excelling in domain-specific, transparent, and multilingual reasoning.</p>\n<p><img alt=\"magistral small comparison to medium\" src=\"/assets/library/magistral/c57cd779-0588-4d74-9f48-89ba50f7a565\"/></p>\n<p><img alt=\"magistral small\" src=\"/assets/library/magistral/fe972176-2881-42bc-bbd8-90a079188aa9\"/></p>\n<h3>Key features</h3>\n<ul>\n<li><strong>Reasoning:</strong>\u00a0Capable of long chains of reasoning traces before providing an answer.</li>\n<li><strong>Multilingual:</strong>\u00a0Supports dozens of languages, including English, French, German, Greek, Hindi, Indonesian, Italian, Japanese, Korean, Malay, Nepali, Polish, Portuguese, Romanian, Russian, Serbian, Spanish, Swedish, Turkish, Ukrainian, Vietnamese, Arabic, Bengali, Chinese, and Farsi.</li>\n<li><strong>Apache 2.0 License:</strong>\u00a0Open license allowing usage and modification for both commercial and non-commercial purposes.</li>\n<li><strong>Context Window:</strong>\u00a0A 128k context window,\u00a0<strong>but</strong>\u00a0performance might degrade past\u00a0<strong>40k</strong>. Hence we recommend setting the maximum model length to 40k.</li>\n</ul>\n<p>Magistral is ideal for general purpose use requiring longer thought processing and better accuracy than with non-reasoning LLMs. From legal research and financial forecasting to software development and creative storytelling \u2014 this model solves multi-step challenges where transparency and precision are critical.</p>\n<h4>Business strategy and operations.</h4>\n<p>Building on our flagship\u00a0<a href=\"https://mistral.ai/models\" rel=\"nofollow\">models</a>, Magistral is designed for research, strategic planning, operational optimization, and data-driven decision making \u2014 whether executing risk assessment and modelling with multiple factors, or calculating optimal delivery windows under constraints.</p>\n<h4>Regulated industries and sectors.</h4>\n<p>Legal, finance, healthcare, and government professionals get traceable reasoning that meets compliance requirements. Every conclusion can be traced back through its logical steps, providing auditability for high-stakes environments with domain-specialized AI.</p>\n<h4>Systems, software, and data engineering.</h4>\n<p>Magistral enhances coding and development use cases: compared to non-reasoning models, it significantly improves project planning, backend architecture, frontend design, and data engineering through sequenced, multi-step actions involving external tools or API.</p>\n<h4>Content and communication.</h4>\n<p>Our early tests indicated that Magistral is an excellent creative companion. We highly recommend it for creative writing and storytelling, with the model capable of producing coherent or \u2014 if needed \u2014 delightfully eccentric copy.</p>\n<h3>Reference</h3>\n<ul>\n<li><a href=\"https://mistral.ai/static/research/magistral.pdf\" rel=\"nofollow\">Magistral paper</a></li>\n<li><a href=\"https://mistral.ai/news/magistral\" rel=\"nofollow\">Blog post</a></li>\n</ul>\n</div>",
  "page_hash": "a05171f395db",
  "readme_text": "\n\nMagistral is the first reasoning model by Mistral AI, excelling in domain-specific, transparent, and multilingual reasoning.\n\n\nKey features\n\nReasoning:\u00a0Capable of long chains of reasoning traces before providing an answer.\nMultilingual:\u00a0Supports dozens of languages, including English, French, German, Greek, Hindi, Indonesian, Italian, Japanese, Korean, Malay, Nepali, Polish, Portuguese, Romanian, Russian, Serbian, Spanish, Swedish, Turkish, Ukrainian, Vietnamese, Arabic, Bengali, Chinese, and Farsi.\nApache 2.0 License:\u00a0Open license allowing usage and modification for both commercial and non-commercial purposes.\nContext Window:\u00a0A 128k context window,\u00a0but\u00a0performance might degrade past\u00a040k. Hence we recommend setting the maximum model length to 40k.\n\nMagistral is ideal for general purpose use requiring longer thought processing and better accuracy than with non-reasoning LLMs. From legal research and financial forecasting to software development and creative storytelling \u2014 this model solves multi-step challenges where transparency and precision are critical.\nBusiness strategy and operations.\nBuilding on our flagship\u00a0models, Magistral is designed for research, strategic planning, operational optimization, and data-driven decision making \u2014 whether executing risk assessment and modelling with multiple factors, or calculating optimal delivery windows under constraints.\nRegulated industries and sectors.\nLegal, finance, healthcare, and government professionals get traceable reasoning that meets compliance requirements. Every conclusion can be traced back through its logical steps, providing auditability for high-stakes environments with domain-specialized AI.\nSystems, software, and data engineering.\nMagistral enhances coding and development use cases: compared to non-reasoning models, it significantly improves project planning, backend architecture, frontend design, and data engineering through sequenced, multi-step actions involving external tools or API.\nContent and communication.\nOur early tests indicated that Magistral is an excellent creative companion. We highly recommend it for creative writing and storytelling, with the model capable of producing coherent or \u2014 if needed \u2014 delightfully eccentric copy.\nReference\n\nMagistral paper\nBlog post\n\n",
  "tags": [
    {
      "tag": "magistral:latest",
      "last_updated": "1 month ago",
      "size": "14GB",
      "digest": "sha256:7b3169d5ab3b9827cbb05408e6054610735c1c8b83d8691152ee21d89c34018e",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:7b3169d5ab3b9827cbb05408e6054610735c1c8b83d8691152ee21d89c34018e",
          "size": 562
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:641615e9986bc8687f936cd87c586bdd92d338172c4180963080e48b8e84ec36",
            "size": 14333907488
          },
          {
            "mediaType": "Template",
            "digest": "sha256:35f7a1efc383aeaa73f17f770de9c1d3531693c65edf1e0cbadea7d17db23fa9",
            "size": 948
          },
          {
            "mediaType": "application/vnd.ollama.image.system",
            "digest": "sha256:43c1db03bf38c4a9a096463d4b9de42ba9e835c084e4c7fdc20ffdef85ec8605",
            "size": 819
          },
          {
            "mediaType": "License",
            "digest": "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "size": 11356
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ba3ab63d35822e9df884ce427fa8f553655296324e035ccf79523e1e293fbd9b",
            "size": 33
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "23.6B",
        "file_type": "Q4_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:641615e9986bc8687f936cd87c586bdd92d338172c4180963080e48b8e84ec36",
            "sha256:e41c8368ce9315b9400f4370ffb7eb1c09f60f025fd31bc05b7d85ea7bed902b",
            "sha256:43c1db03bf38c4a9a096463d4b9de42ba9e835c084e4c7fdc20ffdef85ec8605",
            "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "sha256:ba3ab63d35822e9df884ce427fa8f553655296324e035ccf79523e1e293fbd9b"
          ]
        }
      },
      "context_length": null,
      "model_type": "23.6B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "magistral:24b",
      "last_updated": "1 month ago",
      "size": "14GB",
      "digest": "sha256:7b3169d5ab3b9827cbb05408e6054610735c1c8b83d8691152ee21d89c34018e",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:7b3169d5ab3b9827cbb05408e6054610735c1c8b83d8691152ee21d89c34018e",
          "size": 562
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:641615e9986bc8687f936cd87c586bdd92d338172c4180963080e48b8e84ec36",
            "size": 14333907488
          },
          {
            "mediaType": "Template",
            "digest": "sha256:35f7a1efc383aeaa73f17f770de9c1d3531693c65edf1e0cbadea7d17db23fa9",
            "size": 948
          },
          {
            "mediaType": "application/vnd.ollama.image.system",
            "digest": "sha256:43c1db03bf38c4a9a096463d4b9de42ba9e835c084e4c7fdc20ffdef85ec8605",
            "size": 819
          },
          {
            "mediaType": "License",
            "digest": "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "size": 11356
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ba3ab63d35822e9df884ce427fa8f553655296324e035ccf79523e1e293fbd9b",
            "size": 33
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "23.6B",
        "file_type": "Q4_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:641615e9986bc8687f936cd87c586bdd92d338172c4180963080e48b8e84ec36",
            "sha256:e41c8368ce9315b9400f4370ffb7eb1c09f60f025fd31bc05b7d85ea7bed902b",
            "sha256:43c1db03bf38c4a9a096463d4b9de42ba9e835c084e4c7fdc20ffdef85ec8605",
            "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "sha256:ba3ab63d35822e9df884ce427fa8f553655296324e035ccf79523e1e293fbd9b"
          ]
        }
      },
      "context_length": null,
      "model_type": "23.6B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "magistral:24b-small-2506-q4_K_M",
      "last_updated": "1 month ago",
      "size": "14GB",
      "digest": "sha256:7b3169d5ab3b9827cbb05408e6054610735c1c8b83d8691152ee21d89c34018e",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:7b3169d5ab3b9827cbb05408e6054610735c1c8b83d8691152ee21d89c34018e",
          "size": 562
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:641615e9986bc8687f936cd87c586bdd92d338172c4180963080e48b8e84ec36",
            "size": 14333907488
          },
          {
            "mediaType": "Template",
            "digest": "sha256:35f7a1efc383aeaa73f17f770de9c1d3531693c65edf1e0cbadea7d17db23fa9",
            "size": 948
          },
          {
            "mediaType": "application/vnd.ollama.image.system",
            "digest": "sha256:43c1db03bf38c4a9a096463d4b9de42ba9e835c084e4c7fdc20ffdef85ec8605",
            "size": 819
          },
          {
            "mediaType": "License",
            "digest": "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "size": 11356
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ba3ab63d35822e9df884ce427fa8f553655296324e035ccf79523e1e293fbd9b",
            "size": 33
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "23.6B",
        "file_type": "Q4_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:641615e9986bc8687f936cd87c586bdd92d338172c4180963080e48b8e84ec36",
            "sha256:e41c8368ce9315b9400f4370ffb7eb1c09f60f025fd31bc05b7d85ea7bed902b",
            "sha256:43c1db03bf38c4a9a096463d4b9de42ba9e835c084e4c7fdc20ffdef85ec8605",
            "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "sha256:ba3ab63d35822e9df884ce427fa8f553655296324e035ccf79523e1e293fbd9b"
          ]
        }
      },
      "context_length": null,
      "model_type": "23.6B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "magistral:24b-small-2506-q8_0",
      "last_updated": "1 month ago",
      "size": "25GB",
      "digest": "sha256:2a44df1f3a7129c0391058306aea87d0ed19519c5d2412fc20aab24584807886",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:2a44df1f3a7129c0391058306aea87d0ed19519c5d2412fc20aab24584807886",
          "size": 560
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:a95c7057be72e9b33ba85853233766a404b8347cb98ef3fea05f93b92d0d832a",
            "size": 25054777888
          },
          {
            "mediaType": "Template",
            "digest": "sha256:35f7a1efc383aeaa73f17f770de9c1d3531693c65edf1e0cbadea7d17db23fa9",
            "size": 948
          },
          {
            "mediaType": "application/vnd.ollama.image.system",
            "digest": "sha256:43c1db03bf38c4a9a096463d4b9de42ba9e835c084e4c7fdc20ffdef85ec8605",
            "size": 819
          },
          {
            "mediaType": "License",
            "digest": "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "size": 11356
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ba3ab63d35822e9df884ce427fa8f553655296324e035ccf79523e1e293fbd9b",
            "size": 33
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "23.6B",
        "file_type": "Q8_0",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:a95c7057be72e9b33ba85853233766a404b8347cb98ef3fea05f93b92d0d832a",
            "sha256:e41c8368ce9315b9400f4370ffb7eb1c09f60f025fd31bc05b7d85ea7bed902b",
            "sha256:43c1db03bf38c4a9a096463d4b9de42ba9e835c084e4c7fdc20ffdef85ec8605",
            "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "sha256:ba3ab63d35822e9df884ce427fa8f553655296324e035ccf79523e1e293fbd9b"
          ]
        }
      },
      "context_length": null,
      "model_type": "23.6B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "magistral:24b-small-2506-fp16",
      "last_updated": "1 month ago",
      "size": "47GB",
      "digest": "sha256:f9393ba5014439896269ff08893ed8b33049c7631f51c61a41a62fa20fb94e08",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:f9393ba5014439896269ff08893ed8b33049c7631f51c61a41a62fa20fb94e08",
          "size": 559
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:5a648ad1d454a63637866e95bd549b6b3ecae56ff6f889407dc4a7b07ed57208",
            "size": 47153517024,
            "from": "/Users/ollama/.ollama/models/blobs/sha256-5a648ad1d454a63637866e95bd549b6b3ecae56ff6f889407dc4a7b07ed57208"
          },
          {
            "mediaType": "Template",
            "digest": "sha256:35f7a1efc383aeaa73f17f770de9c1d3531693c65edf1e0cbadea7d17db23fa9",
            "size": 948
          },
          {
            "mediaType": "application/vnd.ollama.image.system",
            "digest": "sha256:43c1db03bf38c4a9a096463d4b9de42ba9e835c084e4c7fdc20ffdef85ec8605",
            "size": 819
          },
          {
            "mediaType": "License",
            "digest": "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "size": 11356
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ba3ab63d35822e9df884ce427fa8f553655296324e035ccf79523e1e293fbd9b",
            "size": 33
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "23.6B",
        "file_type": "F16",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:5a648ad1d454a63637866e95bd549b6b3ecae56ff6f889407dc4a7b07ed57208",
            "sha256:e41c8368ce9315b9400f4370ffb7eb1c09f60f025fd31bc05b7d85ea7bed902b",
            "sha256:43c1db03bf38c4a9a096463d4b9de42ba9e835c084e4c7fdc20ffdef85ec8605",
            "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "sha256:ba3ab63d35822e9df884ce427fa8f553655296324e035ccf79523e1e293fbd9b"
          ]
        }
      },
      "context_length": null,
      "model_type": "23.6B",
      "quantization": null,
      "base_model": null
    }
  ],
  "quality_score": {
    "fields_filled": 12,
    "total_possible": 19,
    "completeness": 0.63
  }
}