{
  "name": "command-a",
  "description": "111 billion parameter model optimized for demanding enterprises that require fast, secure, and high-quality AI",
  "pull_count": 21300,
  "last_updated": "Mar 13, 2025 12:39 PM UTC",
  "readme_html": "<div class=\"prose-td code:display-inline-block prose-td code:bg-gray-200 prose-td code:px-2 prose-td code:py-1 prose-td code:rounded-md prose prose-headings:mb-[0.7em] prose-headings:mt-[1.25em] prose-headings:font-semibold prose-headings:tracking-tight prose-h1:text-[32px] prose-h2:text-2xl prose-h3:text-xl prose-h4:text-lg prose-h5:text-base prose-p:mb-4 prose-p:mt-0 prose-p:leading-relaxed prose-p:before:hidden prose-p:after:hidden prose-blockquote:font-normal prose-blockquote:not-italic prose-blockquote:text-neutral-500 prose-blockquote:before:hidden prose-blockquote:after:hidden prose-code:my-0 prose-code:inline-block prose-code:rounded-md prose-code:bg-neutral-100 prose-code:px-2 prose-code:text-[85%] prose-code:font-normal prose-code:leading-relaxed prose-code:text-black prose-code:before:hidden prose-code:after:hidden prose-pre:mb-4 prose-pre:mt-0 prose-pre:whitespace-pre-wrap prose-pre:rounded-lg prose-pre:bg-neutral-100 prose-pre:px-3 prose-pre:py-3 prose-pre:text-base prose-pre:text-black prose-ol:mb-4 prose-ol:mt-1 prose-ol:pl-8 marker:prose-ol:text-black prose-ul:mb-4 prose-ul:mt-1 prose-ul:pl-8 marker:prose-ul:text-black prose-li:mb-0 prose-li:mt-0.5 prose-li:text-black first:prose-li:mt-0 prose-table:w-full prose-table:table-auto prose-table:border-collapse prose-th:break-words prose-th:text-center prose-th:font-semibold prose-td:break-words prose-td:px-4 prose-td:py-2 prose-td:text-left prose-img:mx-auto prose-img:my-12 prose-video:my-12 max-w-none overflow-auto py-5 text-black\" id=\"display\">\n<p><img alt=\"Hero-Image.webp\" src=\"/assets/library/command-a/5849b9b2-34cd-4827-92d4-97613dc8a5e5\"/></p>\n<p>Command A is an open weights research release of a 111 billion parameter model optimized for demanding enterprises that require fast, secure, and high-quality AI. Compared to other leading proprietary and open-weights models Command A delivers maximum performance with minimum hardware costs, excelling on business-critical agentic and multilingual tasks while\u202c being deployable on just two GPUs.</p>\n<p><strong>Languages covered:</strong> The model has been trained on 23 languages: English, French, Spanish, Italian, German, Portuguese, Japanese, Korean, Arabic, Chinese, Russian, Polish, Turkish, Vietnamese, Dutch, Czech, Indonesian, Ukrainian, Romanian, Greek, Hindi, Hebrew, and Persian.</p>\n<p><strong>Context Window:</strong> Up to 256K.</p>\n<h3>Use cases</h3>\n<p>Command A is designed with the following capabilities.</p>\n<h4>Chat</h4>\n<p>By default, Command A is configured as a conversational model. A preamble conditions the model on interactive behaviour, meaning it is expected to reply in a conversational fashion, provides introductory statements and follow-up questions, and uses Markdown as well as LaTeX where appropriate. This is desired for interactive experiences, such as chatbots, where the model engages in dialogue.</p>\n<h4>Retrieval augmented generation (RAG)</h4>\n<p>Command A has been trained specifically for tasks like the final step of Retrieval Augmented Generation (RAG).</p>\n<h4>Tool Support</h4>\n<p>Command A has been specifically trained with conversational tool use capabilities. This allows the model to interact with external tools like APIs, databases, or search engines.</p>\n<h4>Code</h4>\n<p>Command A has meaningfully improved on code capabilities.  In addition to academic code benchmarks, we have evaluated it on enterprise-relevant scenarios, including SQL generation and code translation, where it outperforms other models of similar size. Try these out by requesting code snippets, code explanations, or code rewrites. For better performance, we also recommend using a low temperature (and even greedy decoding) for code-generation related instructions.</p>\n</div>",
  "page_hash": "8e5d494155e8",
  "readme_text": "\n\nCommand A is an open weights research release of a 111 billion parameter model optimized for demanding enterprises that require fast, secure, and high-quality AI. Compared to other leading proprietary and open-weights models Command A delivers maximum performance with minimum hardware costs, excelling on business-critical agentic and multilingual tasks while\u202c being deployable on just two GPUs.\nLanguages covered: The model has been trained on 23 languages: English, French, Spanish, Italian, German, Portuguese, Japanese, Korean, Arabic, Chinese, Russian, Polish, Turkish, Vietnamese, Dutch, Czech, Indonesian, Ukrainian, Romanian, Greek, Hindi, Hebrew, and Persian.\nContext Window: Up to 256K.\nUse cases\nCommand A is designed with the following capabilities.\nChat\nBy default, Command A is configured as a conversational model. A preamble conditions the model on interactive behaviour, meaning it is expected to reply in a conversational fashion, provides introductory statements and follow-up questions, and uses Markdown as well as LaTeX where appropriate. This is desired for interactive experiences, such as chatbots, where the model engages in dialogue.\nRetrieval augmented generation (RAG)\nCommand A has been trained specifically for tasks like the final step of Retrieval Augmented Generation (RAG).\nTool Support\nCommand A has been specifically trained with conversational tool use capabilities. This allows the model to interact with external tools like APIs, databases, or search engines.\nCode\nCommand A has meaningfully improved on code capabilities.  In addition to academic code benchmarks, we have evaluated it on enterprise-relevant scenarios, including SQL generation and code translation, where it outperforms other models of similar size. Try these out by requesting code snippets, code explanations, or code rewrites. For better performance, we also recommend using a low temperature (and even greedy decoding) for code-generation related instructions.\n",
  "tags": [
    {
      "tag": "command-a:latest",
      "last_updated": "4 months ago",
      "size": "67GB",
      "digest": "sha256:e7dbe88885378de6cb2e99bbfbcd55b976c3ca6cf8443713b4b5f47cf7f7c993",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:e7dbe88885378de6cb2e99bbfbcd55b976c3ca6cf8443713b4b5f47cf7f7c993",
          "size": 493
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:ffd0081a97182da52ef3c58dcafde851cbd436ce82f71fc5ed9973828bf78a8f",
            "size": 67135509120
          },
          {
            "mediaType": "Template",
            "digest": "sha256:0d8282caa612c1f8fea92cac270905dcd27403272abdfb4edc58627eb7b0d327",
            "size": 7213
          },
          {
            "mediaType": "License",
            "digest": "sha256:945eaa8b14280408800a409b7db5d18dbb266a21610d85cb8eb32c93c3243f90",
            "size": 13880
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:d8455b5dce0b7033b50d071d5101110958ee93d681157ae9094aa1b3615d4660",
            "size": 110
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "cohere2",
        "model_families": [
          "cohere2"
        ],
        "model_type": "111.1B",
        "file_type": "Q4_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:ffd0081a97182da52ef3c58dcafde851cbd436ce82f71fc5ed9973828bf78a8f",
            "sha256:0d8282caa612c1f8fea92cac270905dcd27403272abdfb4edc58627eb7b0d327",
            "sha256:945eaa8b14280408800a409b7db5d18dbb266a21610d85cb8eb32c93c3243f90",
            "sha256:d8455b5dce0b7033b50d071d5101110958ee93d681157ae9094aa1b3615d4660"
          ]
        }
      },
      "context_length": null,
      "model_type": "111.1B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "command-a:111b",
      "last_updated": "4 months ago",
      "size": "67GB",
      "digest": "sha256:e7dbe88885378de6cb2e99bbfbcd55b976c3ca6cf8443713b4b5f47cf7f7c993",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:e7dbe88885378de6cb2e99bbfbcd55b976c3ca6cf8443713b4b5f47cf7f7c993",
          "size": 493
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:ffd0081a97182da52ef3c58dcafde851cbd436ce82f71fc5ed9973828bf78a8f",
            "size": 67135509120
          },
          {
            "mediaType": "Template",
            "digest": "sha256:0d8282caa612c1f8fea92cac270905dcd27403272abdfb4edc58627eb7b0d327",
            "size": 7213
          },
          {
            "mediaType": "License",
            "digest": "sha256:945eaa8b14280408800a409b7db5d18dbb266a21610d85cb8eb32c93c3243f90",
            "size": 13880
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:d8455b5dce0b7033b50d071d5101110958ee93d681157ae9094aa1b3615d4660",
            "size": 110
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "cohere2",
        "model_families": [
          "cohere2"
        ],
        "model_type": "111.1B",
        "file_type": "Q4_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:ffd0081a97182da52ef3c58dcafde851cbd436ce82f71fc5ed9973828bf78a8f",
            "sha256:0d8282caa612c1f8fea92cac270905dcd27403272abdfb4edc58627eb7b0d327",
            "sha256:945eaa8b14280408800a409b7db5d18dbb266a21610d85cb8eb32c93c3243f90",
            "sha256:d8455b5dce0b7033b50d071d5101110958ee93d681157ae9094aa1b3615d4660"
          ]
        }
      },
      "context_length": null,
      "model_type": "111.1B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "command-a:111b-03-2025-q4_K_M",
      "last_updated": "4 months ago",
      "size": "67GB",
      "digest": "sha256:e7dbe88885378de6cb2e99bbfbcd55b976c3ca6cf8443713b4b5f47cf7f7c993",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:e7dbe88885378de6cb2e99bbfbcd55b976c3ca6cf8443713b4b5f47cf7f7c993",
          "size": 493
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:ffd0081a97182da52ef3c58dcafde851cbd436ce82f71fc5ed9973828bf78a8f",
            "size": 67135509120
          },
          {
            "mediaType": "Template",
            "digest": "sha256:0d8282caa612c1f8fea92cac270905dcd27403272abdfb4edc58627eb7b0d327",
            "size": 7213
          },
          {
            "mediaType": "License",
            "digest": "sha256:945eaa8b14280408800a409b7db5d18dbb266a21610d85cb8eb32c93c3243f90",
            "size": 13880
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:d8455b5dce0b7033b50d071d5101110958ee93d681157ae9094aa1b3615d4660",
            "size": 110
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "cohere2",
        "model_families": [
          "cohere2"
        ],
        "model_type": "111.1B",
        "file_type": "Q4_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:ffd0081a97182da52ef3c58dcafde851cbd436ce82f71fc5ed9973828bf78a8f",
            "sha256:0d8282caa612c1f8fea92cac270905dcd27403272abdfb4edc58627eb7b0d327",
            "sha256:945eaa8b14280408800a409b7db5d18dbb266a21610d85cb8eb32c93c3243f90",
            "sha256:d8455b5dce0b7033b50d071d5101110958ee93d681157ae9094aa1b3615d4660"
          ]
        }
      },
      "context_length": null,
      "model_type": "111.1B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "command-a:111b-03-2025-q8_0",
      "last_updated": "4 months ago",
      "size": "118GB",
      "digest": "sha256:1dc49a16c794884328c37b3b369236d8f7118d1608e9c0c6ea01e501ec29a9ca",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:1dc49a16c794884328c37b3b369236d8f7118d1608e9c0c6ea01e501ec29a9ca",
          "size": 491
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:ab9643964a4643ea26d89a0c5f65d443081420837f00cdc6bd38f4a9e9236ea0",
            "size": 118011957888
          },
          {
            "mediaType": "Template",
            "digest": "sha256:0d8282caa612c1f8fea92cac270905dcd27403272abdfb4edc58627eb7b0d327",
            "size": 7213
          },
          {
            "mediaType": "License",
            "digest": "sha256:945eaa8b14280408800a409b7db5d18dbb266a21610d85cb8eb32c93c3243f90",
            "size": 13880
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:d8455b5dce0b7033b50d071d5101110958ee93d681157ae9094aa1b3615d4660",
            "size": 110
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "cohere2",
        "model_families": [
          "cohere2"
        ],
        "model_type": "111.1B",
        "file_type": "Q8_0",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:ab9643964a4643ea26d89a0c5f65d443081420837f00cdc6bd38f4a9e9236ea0",
            "sha256:0d8282caa612c1f8fea92cac270905dcd27403272abdfb4edc58627eb7b0d327",
            "sha256:945eaa8b14280408800a409b7db5d18dbb266a21610d85cb8eb32c93c3243f90",
            "sha256:d8455b5dce0b7033b50d071d5101110958ee93d681157ae9094aa1b3615d4660"
          ]
        }
      },
      "context_length": null,
      "model_type": "111.1B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "command-a:111b-03-2025-fp16",
      "last_updated": "4 months ago",
      "size": "222GB",
      "digest": "sha256:aa05fc87489a801677dc91d67922f2573f8644a141e94451c97517bbabd27720",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:aa05fc87489a801677dc91d67922f2573f8644a141e94451c97517bbabd27720",
          "size": 490
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:b49fe64ba66a87d5cf06c4a8df026fa61243320f752a1e9fff37e991212c62a8",
            "size": 222127690368,
            "from": "/Users/ollama/.ollama/models/blobs/sha256-b49fe64ba66a87d5cf06c4a8df026fa61243320f752a1e9fff37e991212c62a8"
          },
          {
            "mediaType": "Template",
            "digest": "sha256:0d8282caa612c1f8fea92cac270905dcd27403272abdfb4edc58627eb7b0d327",
            "size": 7213
          },
          {
            "mediaType": "License",
            "digest": "sha256:945eaa8b14280408800a409b7db5d18dbb266a21610d85cb8eb32c93c3243f90",
            "size": 13880
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:d8455b5dce0b7033b50d071d5101110958ee93d681157ae9094aa1b3615d4660",
            "size": 110
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "cohere2",
        "model_families": [
          "cohere2"
        ],
        "model_type": "111.1B",
        "file_type": "F16",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:b49fe64ba66a87d5cf06c4a8df026fa61243320f752a1e9fff37e991212c62a8",
            "sha256:0d8282caa612c1f8fea92cac270905dcd27403272abdfb4edc58627eb7b0d327",
            "sha256:945eaa8b14280408800a409b7db5d18dbb266a21610d85cb8eb32c93c3243f90",
            "sha256:d8455b5dce0b7033b50d071d5101110958ee93d681157ae9094aa1b3615d4660"
          ]
        }
      },
      "context_length": null,
      "model_type": "111.1B",
      "quantization": null,
      "base_model": null
    }
  ],
  "annotations": {
    "ollama.input_type": "chat"
  },
  "quality_score": {
    "fields_filled": 11,
    "total_possible": 19,
    "completeness": 0.58
  }
}