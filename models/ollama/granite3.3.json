{
  "name": "granite3.3",
  "description": "IBM Granite 2B and 8B models are 128K context length language models that have been fine-tuned for improved reasoning and instruction-following capabilities.",
  "license": "",
  "pull_count": 207200,
  "last_updated": "Apr 16, 2025 2:49 PM UTC",
  "readme_html": "<div class=\"prose-td code:display-inline-block prose-td code:bg-gray-200 prose-td code:px-2 prose-td code:py-1 prose-td code:rounded-md prose prose-headings:mb-[0.7em] prose-headings:mt-[1.25em] prose-headings:font-semibold prose-headings:tracking-tight prose-h1:text-[32px] prose-h2:text-2xl prose-h3:text-xl prose-h4:text-lg prose-h5:text-base prose-p:mb-4 prose-p:mt-0 prose-p:leading-relaxed prose-p:before:hidden prose-p:after:hidden prose-blockquote:font-normal prose-blockquote:not-italic prose-blockquote:text-neutral-500 prose-blockquote:before:hidden prose-blockquote:after:hidden prose-code:my-0 prose-code:inline-block prose-code:rounded-md prose-code:bg-neutral-100 prose-code:px-2 prose-code:text-[85%] prose-code:font-normal prose-code:leading-relaxed prose-code:text-black prose-code:before:hidden prose-code:after:hidden prose-pre:mb-4 prose-pre:mt-0 prose-pre:whitespace-pre-wrap prose-pre:rounded-lg prose-pre:bg-neutral-100 prose-pre:px-3 prose-pre:py-3 prose-pre:text-base prose-pre:text-black prose-ol:mb-4 prose-ol:mt-1 prose-ol:pl-8 marker:prose-ol:text-black prose-ul:mb-4 prose-ul:mt-1 prose-ul:pl-8 marker:prose-ul:text-black prose-li:mb-0 prose-li:mt-0.5 prose-li:text-black first:prose-li:mt-0 prose-table:w-full prose-table:table-auto prose-table:border-collapse prose-th:break-words prose-th:text-center prose-th:font-semibold prose-td:break-words prose-td:px-4 prose-td:py-2 prose-td:text-left prose-img:mx-auto prose-img:my-12 prose-video:my-12 max-w-none overflow-auto py-5 text-black\" id=\"display\">\n<p><img src=\"/assets/library/granite3.2/90c5e567-0004-425c-a17a-1b846c2b5d3d\" width=\"600\"/></p>\n<h2>Granite 3.3</h2>\n<p>The IBM Granite <strong>2B and 8B models</strong> are 128K context length language models that have been fine-tuned for improved reasoning and instruction-following capabilities. These models deliver significant gains on benchmarks for measuring generic performance including AlpacaEval-2.0 and Arena-Hard, and improvements in mathematics, coding, and instruction following. They also supports Fill-in-the-Middle (FIM) for code completion tasks and structured reasoning.</p>\n<h3>Parameter Sizes</h3>\n<p><strong>2B:</strong></p>\n<p><code>ollama run granite3.3:2b</code></p>\n<p><strong>8B:</strong></p>\n<p><code>ollama run granite3.3:8b</code></p>\n<h3>Supported Languages</h3>\n<p>English, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, and Chinese. However, users may finetune this Granite model for languages beyond these 12 languages.</p>\n<h3>Intended Use</h3>\n<p>These models are designed to handle general instruction-following tasks and can be integrated into AI assistants across various domains, including business applications.</p>\n<h3>Capabilities</h3>\n<ul>\n<li>Thinking</li>\n<li>Summarization</li>\n<li>Text classification</li>\n<li>Text extraction</li>\n<li>Question-answering</li>\n<li>Retrieval Augmented Generation (RAG)</li>\n<li>Code related tasks</li>\n<li>Function-calling tasks</li>\n<li>Multilingual dialog use cases</li>\n<li>Fill-in-the-middle</li>\n<li>Long-context tasks including long document/meeting summarization, long document QA, etc.</li>\n</ul>\n<h3>Thinking</h3>\n<p>To enable thinking, add a message with \u201crole\u201d: \u201ccontrol\u201d and set \u201ccontent\u201d to \u201cthinking\u201d. For example:</p>\n<pre><code>{\n    \"messages\": [\n        {\"role\": \"control\", \"content\": \"thinking\"},\n        {\"role\": \"user\", \"content\": \"How do I get to the airport if my car won't start?\"}\n    ]\n}\n</code></pre>\n<h2>Learn more</h2>\n<ul>\n<li><strong>Developers:</strong> IBM Research</li>\n<li><strong>Website</strong>: <a href=\"https://www.ibm.com/granite/docs/\" rel=\"nofollow\">Granite Docs</a></li>\n<li><strong>Release Date</strong>: April 16th, 2025</li>\n<li><strong>License:</strong> <a href=\"https://www.apache.org/licenses/LICENSE-2.0\" rel=\"nofollow\">Apache 2.0</a></li>\n</ul>\n</div>",
  "page_hash": "73cee335432a",
  "readme_text": "\n\nGranite 3.3\nThe IBM Granite 2B and 8B models are 128K context length language models that have been fine-tuned for improved reasoning and instruction-following capabilities. These models deliver significant gains on benchmarks for measuring generic performance including AlpacaEval-2.0 and Arena-Hard, and improvements in mathematics, coding, and instruction following. They also supports Fill-in-the-Middle (FIM) for code completion tasks and structured reasoning.\nParameter Sizes\n2B:\nollama run granite3.3:2b\n8B:\nollama run granite3.3:8b\nSupported Languages\nEnglish, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, and Chinese. However, users may finetune this Granite model for languages beyond these 12 languages.\nIntended Use\nThese models are designed to handle general instruction-following tasks and can be integrated into AI assistants across various domains, including business applications.\nCapabilities\n\nThinking\nSummarization\nText classification\nText extraction\nQuestion-answering\nRetrieval Augmented Generation (RAG)\nCode related tasks\nFunction-calling tasks\nMultilingual dialog use cases\nFill-in-the-middle\nLong-context tasks including long document/meeting summarization, long document QA, etc.\n\nThinking\nTo enable thinking, add a message with \u201crole\u201d: \u201ccontrol\u201d and set \u201ccontent\u201d to \u201cthinking\u201d. For example:\n{\n    \"messages\": [\n        {\"role\": \"control\", \"content\": \"thinking\"},\n        {\"role\": \"user\", \"content\": \"How do I get to the airport if my car won't start?\"}\n    ]\n}\n\nLearn more\n\nDevelopers: IBM Research\nWebsite: Granite Docs\nRelease Date: April 16th, 2025\nLicense: Apache 2.0\n\n",
  "tags": [
    {
      "tag": "granite3.3:latest",
      "last_updated": "3 months ago",
      "size": "4.9GB",
      "digest": "sha256:122661774644959cd109295a907dc4305a7b72f9ce8b9ba0fe43dd2393a7becd",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:122661774644959cd109295a907dc4305a7b72f9ce8b9ba0fe43dd2393a7becd",
          "size": 417
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:77bcee066a76dcdd10d0d123c87e32c8ec2c74e31b6ffd87ebee49c9ac215dca",
            "size": 4942873344,
            "from": "/Users/ollama/.ollama/models/blobs/sha256-77bcee066a76dcdd10d0d123c87e32c8ec2c74e31b6ffd87ebee49c9ac215dca"
          },
          {
            "mediaType": "Template",
            "digest": "sha256:3da071a01bbe5a1aa1e9766149ff67ed2b232f63d55e6ed50e3777b74536a67f",
            "size": 6560
          },
          {
            "mediaType": "License",
            "digest": "sha256:4a99a6dd617d9f901f29fe91925d5032600fcd78f315a9fa78c1667c950a3a5f",
            "size": 11332
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "granite",
        "model_families": [
          "granite"
        ],
        "model_type": "8.2B",
        "file_type": "Q4_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:77bcee066a76dcdd10d0d123c87e32c8ec2c74e31b6ffd87ebee49c9ac215dca",
            "sha256:3da071a01bbe5a1aa1e9766149ff67ed2b232f63d55e6ed50e3777b74536a67f",
            "sha256:4a99a6dd617d9f901f29fe91925d5032600fcd78f315a9fa78c1667c950a3a5f"
          ]
        }
      },
      "context_length": null,
      "model_type": "8.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "granite3.3:2b",
      "last_updated": "3 months ago",
      "size": "1.5GB",
      "digest": "sha256:f9ed27df66e9a0484b0bc04ae1cbcea5a2a0216ad2b0b673a63b9b8a120d06f1",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:f9ed27df66e9a0484b0bc04ae1cbcea5a2a0216ad2b0b673a63b9b8a120d06f1",
          "size": 417
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:ac71e9e32c0bea919b409c5918f69ca74339854b0319c5065e4e9fb6d95c4852",
            "size": 1545303328,
            "from": "/Users/ollama/.ollama/models/blobs/sha256-ac71e9e32c0bea919b409c5918f69ca74339854b0319c5065e4e9fb6d95c4852"
          },
          {
            "mediaType": "Template",
            "digest": "sha256:3da071a01bbe5a1aa1e9766149ff67ed2b232f63d55e6ed50e3777b74536a67f",
            "size": 6560
          },
          {
            "mediaType": "License",
            "digest": "sha256:4a99a6dd617d9f901f29fe91925d5032600fcd78f315a9fa78c1667c950a3a5f",
            "size": 11332
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "granite",
        "model_families": [
          "granite"
        ],
        "model_type": "2.5B",
        "file_type": "Q4_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:ac71e9e32c0bea919b409c5918f69ca74339854b0319c5065e4e9fb6d95c4852",
            "sha256:3da071a01bbe5a1aa1e9766149ff67ed2b232f63d55e6ed50e3777b74536a67f",
            "sha256:4a99a6dd617d9f901f29fe91925d5032600fcd78f315a9fa78c1667c950a3a5f"
          ]
        }
      },
      "context_length": null,
      "model_type": "2.5B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "granite3.3:8b",
      "last_updated": "3 months ago",
      "size": "4.9GB",
      "digest": "sha256:122661774644959cd109295a907dc4305a7b72f9ce8b9ba0fe43dd2393a7becd",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:122661774644959cd109295a907dc4305a7b72f9ce8b9ba0fe43dd2393a7becd",
          "size": 417
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:77bcee066a76dcdd10d0d123c87e32c8ec2c74e31b6ffd87ebee49c9ac215dca",
            "size": 4942873344,
            "from": "/Users/ollama/.ollama/models/blobs/sha256-77bcee066a76dcdd10d0d123c87e32c8ec2c74e31b6ffd87ebee49c9ac215dca"
          },
          {
            "mediaType": "Template",
            "digest": "sha256:3da071a01bbe5a1aa1e9766149ff67ed2b232f63d55e6ed50e3777b74536a67f",
            "size": 6560
          },
          {
            "mediaType": "License",
            "digest": "sha256:4a99a6dd617d9f901f29fe91925d5032600fcd78f315a9fa78c1667c950a3a5f",
            "size": 11332
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "granite",
        "model_families": [
          "granite"
        ],
        "model_type": "8.2B",
        "file_type": "Q4_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:77bcee066a76dcdd10d0d123c87e32c8ec2c74e31b6ffd87ebee49c9ac215dca",
            "sha256:3da071a01bbe5a1aa1e9766149ff67ed2b232f63d55e6ed50e3777b74536a67f",
            "sha256:4a99a6dd617d9f901f29fe91925d5032600fcd78f315a9fa78c1667c950a3a5f"
          ]
        }
      },
      "context_length": null,
      "model_type": "8.2B",
      "quantization": null,
      "base_model": null
    }
  ],
  "annotations": {
    "ollama.input_type": "code"
  },
  "quality_score": {
    "fields_filled": 9,
    "total_possible": 15,
    "completeness": 0.6
  }
}