{
  "name": "minicpm-v",
  "description": "A series of multimodal LLMs (MLLMs) designed for vision-language understanding.",
  "pull_count": 2300000,
  "last_updated": "Nov 18, 2024 7:03 AM UTC",
  "page_hash": "ef79bb7382eb",
  "tags": [
    {
      "name": "application/vnd.ollama.image.model",
      "digest": "sha256:262843d4806aeb402336980badd414a72576b20b1e5d537647da15f16c4a4df0",
      "size": "4.13GB",
      "media_type": "application/vnd.ollama.image.model",
      "annotations": {}
    },
    {
      "name": "application/vnd.ollama.image.projector",
      "digest": "sha256:f8a805e9e62085805c69c427287acefc284932eb4abfe6e1b1ce431d27e2f4e0",
      "size": "0.97GB",
      "media_type": "application/vnd.ollama.image.projector",
      "annotations": {}
    },
    {
      "name": "application/vnd.ollama.image.template",
      "digest": "sha256:60ed67c565f89a3cd5dfa4a142270b88a1f7e9b6e6de416e9961b1ccfcaec360",
      "size": "0.0GB",
      "media_type": "application/vnd.ollama.image.template",
      "annotations": {}
    },
    {
      "name": "application/vnd.ollama.image.license",
      "digest": "sha256:8603ca877636626b927fbed6fef315f854f6fc78588c1ad282d57bd465fd37df",
      "size": "0.0GB",
      "media_type": "application/vnd.ollama.image.license",
      "annotations": {}
    },
    {
      "name": "application/vnd.ollama.image.params",
      "digest": "sha256:f02dd72bb2423204352eabc5637b44d79d17f109fdb510a7c51455892aa2d216",
      "size": "0.0GB",
      "media_type": "application/vnd.ollama.image.params",
      "annotations": {}
    }
  ]
}