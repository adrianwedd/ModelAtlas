{
  "name": "bge-large",
  "description": "Embedding model from BAAI mapping texts to vectors.",
  "pull_count": 113000,
  "last_updated": "Aug 7, 2024 12:04 AM UTC",
  "readme_html": "<div class=\"prose-td code:display-inline-block prose-td code:bg-gray-200 prose-td code:px-2 prose-td code:py-1 prose-td code:rounded-md prose prose-headings:mb-[0.7em] prose-headings:mt-[1.25em] prose-headings:font-semibold prose-headings:tracking-tight prose-h1:text-[32px] prose-h2:text-2xl prose-h3:text-xl prose-h4:text-lg prose-h5:text-base prose-p:mb-4 prose-p:mt-0 prose-p:leading-relaxed prose-p:before:hidden prose-p:after:hidden prose-blockquote:font-normal prose-blockquote:not-italic prose-blockquote:text-neutral-500 prose-blockquote:before:hidden prose-blockquote:after:hidden prose-code:my-0 prose-code:inline-block prose-code:rounded-md prose-code:bg-neutral-100 prose-code:px-2 prose-code:text-[85%] prose-code:font-normal prose-code:leading-relaxed prose-code:text-black prose-code:before:hidden prose-code:after:hidden prose-pre:mb-4 prose-pre:mt-0 prose-pre:whitespace-pre-wrap prose-pre:rounded-lg prose-pre:bg-neutral-100 prose-pre:px-3 prose-pre:py-3 prose-pre:text-base prose-pre:text-black prose-ol:mb-4 prose-ol:mt-1 prose-ol:pl-8 marker:prose-ol:text-black prose-ul:mb-4 prose-ul:mt-1 prose-ul:pl-8 marker:prose-ul:text-black prose-li:mb-0 prose-li:mt-0.5 prose-li:text-black first:prose-li:mt-0 prose-table:w-full prose-table:table-auto prose-table:border-collapse prose-th:break-words prose-th:text-center prose-th:font-semibold prose-td:break-words prose-td:px-4 prose-td:py-2 prose-td:text-left prose-img:mx-auto prose-img:my-12 prose-video:my-12 max-w-none overflow-auto py-5 text-black\" id=\"display\">\n<p>FlagEmbedding can map any text to a low-dimensional dense vector which can be used for tasks like retrieval, classification, clustering, or semantic search. And it also can be used in vector databases for LLMs.</p>\n<pre><code>@misc{bge_embedding,\n      title={C-Pack: Packaged Resources To Advance General Chinese Embedding}, \n      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff},\n      year={2023},\n      eprint={2309.07597},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n</code></pre>\n</div>",
  "page_hash": "6ca68b1166dd",
  "readme_text": "\nFlagEmbedding can map any text to a low-dimensional dense vector which can be used for tasks like retrieval, classification, clustering, or semantic search. And it also can be used in vector databases for LLMs.\n@misc{bge_embedding,\n      title={C-Pack: Packaged Resources To Advance General Chinese Embedding}, \n      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff},\n      year={2023},\n      eprint={2309.07597},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n\n",
  "tags": [
    {
      "tag": "bge-large:latest",
      "last_updated": "11 months ago",
      "size": "671MB",
      "digest": "sha256:917eef6a95d7c6f3b300f430cc3188f86a302ec2e7a7a47790009e32ec91034f",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:917eef6a95d7c6f3b300f430cc3188f86a302ec2e7a7a47790009e32ec91034f",
          "size": 337
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:92b37e50807d951e27ead73c059cf9c3b14941498e37dfde57271e19e6d411df",
            "size": 670530624
          },
          {
            "mediaType": "License",
            "digest": "sha256:a406579cd136771c705c521db86ca7d60a6f3de7c9b5460e6193a2df27861bde",
            "size": 1068
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "bert",
        "model_families": [
          "bert"
        ],
        "model_type": "334.09M",
        "file_type": "F16",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:92b37e50807d951e27ead73c059cf9c3b14941498e37dfde57271e19e6d411df",
            "sha256:a406579cd136771c705c521db86ca7d60a6f3de7c9b5460e6193a2df27861bde"
          ]
        }
      },
      "context_length": null,
      "model_type": "334.09M",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "bge-large:335m",
      "last_updated": "11 months ago",
      "size": "671MB",
      "digest": "sha256:917eef6a95d7c6f3b300f430cc3188f86a302ec2e7a7a47790009e32ec91034f",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:917eef6a95d7c6f3b300f430cc3188f86a302ec2e7a7a47790009e32ec91034f",
          "size": 337
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:92b37e50807d951e27ead73c059cf9c3b14941498e37dfde57271e19e6d411df",
            "size": 670530624
          },
          {
            "mediaType": "License",
            "digest": "sha256:a406579cd136771c705c521db86ca7d60a6f3de7c9b5460e6193a2df27861bde",
            "size": 1068
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "bert",
        "model_families": [
          "bert"
        ],
        "model_type": "334.09M",
        "file_type": "F16",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:92b37e50807d951e27ead73c059cf9c3b14941498e37dfde57271e19e6d411df",
            "sha256:a406579cd136771c705c521db86ca7d60a6f3de7c9b5460e6193a2df27861bde"
          ]
        }
      },
      "context_length": null,
      "model_type": "334.09M",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "bge-large:335m-en-v1.5-fp16",
      "last_updated": "11 months ago",
      "size": "671MB",
      "digest": "sha256:917eef6a95d7c6f3b300f430cc3188f86a302ec2e7a7a47790009e32ec91034f",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:917eef6a95d7c6f3b300f430cc3188f86a302ec2e7a7a47790009e32ec91034f",
          "size": 337
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:92b37e50807d951e27ead73c059cf9c3b14941498e37dfde57271e19e6d411df",
            "size": 670530624
          },
          {
            "mediaType": "License",
            "digest": "sha256:a406579cd136771c705c521db86ca7d60a6f3de7c9b5460e6193a2df27861bde",
            "size": 1068
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "bert",
        "model_families": [
          "bert"
        ],
        "model_type": "334.09M",
        "file_type": "F16",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:92b37e50807d951e27ead73c059cf9c3b14941498e37dfde57271e19e6d411df",
            "sha256:a406579cd136771c705c521db86ca7d60a6f3de7c9b5460e6193a2df27861bde"
          ]
        }
      },
      "context_length": null,
      "model_type": "334.09M",
      "quantization": null,
      "base_model": null
    }
  ],
  "annotations": {
    "ollama.input_type": "text"
  },
  "quality_score": {
    "fields_filled": 9,
    "total_possible": 15,
    "completeness": 0.6
  }
}