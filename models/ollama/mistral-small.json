{
  "name": "mistral-small",
  "description": "Mistral Small 3 sets a new benchmark in the \u201csmall\u201d Large Language Models category below 70B.",
  "license": "",
  "pull_count": 1200000,
  "last_updated": "Jan 30, 2025 3:58 PM UTC",
  "readme_html": "<div class=\"prose-td code:display-inline-block prose-td code:bg-gray-200 prose-td code:px-2 prose-td code:py-1 prose-td code:rounded-md prose prose-headings:mb-[0.7em] prose-headings:mt-[1.25em] prose-headings:font-semibold prose-headings:tracking-tight prose-h1:text-[32px] prose-h2:text-2xl prose-h3:text-xl prose-h4:text-lg prose-h5:text-base prose-p:mb-4 prose-p:mt-0 prose-p:leading-relaxed prose-p:before:hidden prose-p:after:hidden prose-blockquote:font-normal prose-blockquote:not-italic prose-blockquote:text-neutral-500 prose-blockquote:before:hidden prose-blockquote:after:hidden prose-code:my-0 prose-code:inline-block prose-code:rounded-md prose-code:bg-neutral-100 prose-code:px-2 prose-code:text-[85%] prose-code:font-normal prose-code:leading-relaxed prose-code:text-black prose-code:before:hidden prose-code:after:hidden prose-pre:mb-4 prose-pre:mt-0 prose-pre:whitespace-pre-wrap prose-pre:rounded-lg prose-pre:bg-neutral-100 prose-pre:px-3 prose-pre:py-3 prose-pre:text-base prose-pre:text-black prose-ol:mb-4 prose-ol:mt-1 prose-ol:pl-8 marker:prose-ol:text-black prose-ul:mb-4 prose-ul:mt-1 prose-ul:pl-8 marker:prose-ul:text-black prose-li:mb-0 prose-li:mt-0.5 prose-li:text-black first:prose-li:mt-0 prose-table:w-full prose-table:table-auto prose-table:border-collapse prose-th:break-words prose-th:text-center prose-th:font-semibold prose-td:break-words prose-td:px-4 prose-td:py-2 prose-td:text-left prose-img:mx-auto prose-img:my-12 prose-video:my-12 max-w-none overflow-auto py-5 text-black\" id=\"display\">\n<p><img src=\"https://ollama.com/assets/library/mistral-small/87657512-b656-4c53-a8bd-64f0591d6fa9\" width=\"200\"/></p>\n<p>Mistral Small 3 sets a new benchmark in the \u201csmall\u201d Large Language Models category below 70B, boasting 24B parameters and achieving state-of-the-art capabilities comparable to larger models.</p>\n<p>Mistral Small can be deployed locally and is exceptionally \u201cknowledge-dense\u201d, fitting in a single RTX 4090 or a 32GB RAM MacBook once quantized.\nPerfect for:</p>\n<ul>\n<li>Fast response conversational agents.</li>\n<li>Low latency function calling.</li>\n<li>Subject matter experts via fine-tuning.</li>\n<li>Local inference for hobbyists and organizations handling sensitive data.</li>\n</ul>\n<h3>Key Features</h3>\n<ul>\n<li><strong>Multilingual:</strong> Supports dozens of languages, including English, French, German, Spanish, Italian, Chinese, Japanese, Korean, Portuguese, Dutch, and Polish.</li>\n<li><strong>Agent-Centric:</strong> Offers best-in-class agentic capabilities with native function calling and JSON outputting.</li>\n<li><strong>Advanced Reasoning:</strong> State-of-the-art conversational and reasoning capabilities.</li>\n<li><strong>Apache 2.0 License:</strong> Open license allowing usage and modification for both commercial and non-commercial purposes.</li>\n<li><strong>Context Window:</strong> A 32k context window.</li>\n<li><strong>System Prompt:</strong> Maintains strong adherence and support for system prompts.</li>\n<li><strong>Tokenizer:</strong> Utilizes a Tekken tokenizer with a 131k vocabulary size.</li>\n</ul>\n<h3>Human Evaluations</h3>\n<p><img alt=\"Human ratings\" src=\"/assets/library/mistral-small/90f227bd-9751-4fe9-aa23-4d5d89b9d0c6\"/></p>\n<p>We conducted side by side evaluations with an external third-party vendor, on a set of over 1k proprietary coding and generalist prompts. Evaluators were tasked with selecting their preferred model response from anonymized generations produced by Mistral Small 3 vs another model. We are aware that in some cases the benchmarks on human judgement starkly differ from publicly available benchmarks, but have taken extra caution in verifying a fair evaluation. We are confident that the above benchmarks are valid.</p>\n<h3>Instruct performance</h3>\n<p>Our instruction tuned model performs competitively with open weight models three times its size and with proprietary GPT4o-mini model across Code, Math, General knowledge and Instruction following benchmarks.</p>\n<p><img alt=\"instruct performance\" src=\"/assets/library/mistral-small/d27f75e4-0dae-4721-bade-2999a1dd4a7b\"/>\n<img alt=\"instruct performance\" src=\"/assets/library/mistral-small/e677ae9e-edfa-47f9-a35c-b1eb9dfb51c8\"/></p>\n<p><img alt=\"instruct performance\" src=\"/assets/library/mistral-small/4545bb49-d87f-4731-bfdb-e191dc2c2a9a\"/></p>\n<p>Performance accuracy on all benchmarks were obtained through the same internal evaluation pipeline - as such, numbers may vary slightly from previously reported performance (Qwen2.5-32B-Instruct, Llama-3.3-70B-Instruct, Gemma-2-27B-IT). Judge based evals such as Wildbench, Arena hard and MTBench were based on gpt-4o-2024-05-13.</p>\n<p>Customers are evaluating Mistral Small 3 across multiple industries, including:</p>\n<ul>\n<li>Financial services customers for fraud detection</li>\n<li>Healthcare providers for customer triaging</li>\n<li>Robotics, automotive, and manufacturing companies for on-device command and control</li>\n<li>Horizontal use cases across customers include virtual customer service, and sentiment and feedback analysis.</li>\n</ul>\n</div>",
  "page_hash": "b8be30a367fd",
  "readme_text": "\n\nMistral Small 3 sets a new benchmark in the \u201csmall\u201d Large Language Models category below 70B, boasting 24B parameters and achieving state-of-the-art capabilities comparable to larger models.\nMistral Small can be deployed locally and is exceptionally \u201cknowledge-dense\u201d, fitting in a single RTX 4090 or a 32GB RAM MacBook once quantized.\nPerfect for:\n\nFast response conversational agents.\nLow latency function calling.\nSubject matter experts via fine-tuning.\nLocal inference for hobbyists and organizations handling sensitive data.\n\nKey Features\n\nMultilingual: Supports dozens of languages, including English, French, German, Spanish, Italian, Chinese, Japanese, Korean, Portuguese, Dutch, and Polish.\nAgent-Centric: Offers best-in-class agentic capabilities with native function calling and JSON outputting.\nAdvanced Reasoning: State-of-the-art conversational and reasoning capabilities.\nApache 2.0 License: Open license allowing usage and modification for both commercial and non-commercial purposes.\nContext Window: A 32k context window.\nSystem Prompt: Maintains strong adherence and support for system prompts.\nTokenizer: Utilizes a Tekken tokenizer with a 131k vocabulary size.\n\nHuman Evaluations\n\nWe conducted side by side evaluations with an external third-party vendor, on a set of over 1k proprietary coding and generalist prompts. Evaluators were tasked with selecting their preferred model response from anonymized generations produced by Mistral Small 3 vs another model. We are aware that in some cases the benchmarks on human judgement starkly differ from publicly available benchmarks, but have taken extra caution in verifying a fair evaluation. We are confident that the above benchmarks are valid.\nInstruct performance\nOur instruction tuned model performs competitively with open weight models three times its size and with proprietary GPT4o-mini model across Code, Math, General knowledge and Instruction following benchmarks.\n\n\n\nPerformance accuracy on all benchmarks were obtained through the same internal evaluation pipeline - as such, numbers may vary slightly from previously reported performance (Qwen2.5-32B-Instruct, Llama-3.3-70B-Instruct, Gemma-2-27B-IT). Judge based evals such as Wildbench, Arena hard and MTBench were based on gpt-4o-2024-05-13.\nCustomers are evaluating Mistral Small 3 across multiple industries, including:\n\nFinancial services customers for fraud detection\nHealthcare providers for customer triaging\nRobotics, automotive, and manufacturing companies for on-device command and control\nHorizontal use cases across customers include virtual customer service, and sentiment and feedback analysis.\n\n",
  "tags": [
    {
      "tag": "mistral-small:latest",
      "last_updated": "5 months ago",
      "size": "14GB",
      "digest": "sha256:41ffc852c4b6c4804f0520c43a705fd13eb627445bcd80bff8bfa25e09ecd178",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:41ffc852c4b6c4804f0520c43a705fd13eb627445bcd80bff8bfa25e09ecd178",
          "size": 562
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:102a747c137683e81d431dab05d8f2158df4ab6f162f8f9019425a43d51e0e9f",
            "size": 14333908384
          },
          {
            "mediaType": "Template",
            "digest": "sha256:6db27cd4e277c91264572b9c899c1980daa8dea11e902f0070a6f4763f3d13c8",
            "size": 695
          },
          {
            "mediaType": "application/vnd.ollama.image.system",
            "digest": "sha256:6d7b25ffd24789fb9fb5c5ba702a4ae77fa8ba27ecf868442278611161511fc6",
            "size": 644
          },
          {
            "mediaType": "License",
            "digest": "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "size": 11356
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:e0daf17ff83eace4813f9e8554b262f6cc33ad880ff8df41a156ff9ef5522ddb",
            "size": 21
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "23.6B",
        "file_type": "Q4_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:102a747c137683e81d431dab05d8f2158df4ab6f162f8f9019425a43d51e0e9f",
            "sha256:6db27cd4e277c91264572b9c899c1980daa8dea11e902f0070a6f4763f3d13c8",
            "sha256:6d7b25ffd24789fb9fb5c5ba702a4ae77fa8ba27ecf868442278611161511fc6",
            "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "sha256:e0daf17ff83eace4813f9e8554b262f6cc33ad880ff8df41a156ff9ef5522ddb"
          ]
        }
      },
      "context_length": null,
      "model_type": "23.6B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b",
      "last_updated": "10 months ago",
      "size": "13GB",
      "digest": "sha256:183659ffa02e4a94ef89f0a040bb9f5363dfadbdb2433395701feeb1df362595",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:183659ffa02e4a94ef89f0a040bb9f5363dfadbdb2433395701feeb1df362595",
          "size": 486
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:e5f39205cb1323dbfce381f15993d66ec7b40374b2cc1961bdf62828fb9709d1",
            "size": 12569159552
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q4_0",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:e5f39205cb1323dbfce381f15993d66ec7b40374b2cc1961bdf62828fb9709d1",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:24b",
      "last_updated": "5 months ago",
      "size": "14GB",
      "digest": "sha256:41ffc852c4b6c4804f0520c43a705fd13eb627445bcd80bff8bfa25e09ecd178",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:41ffc852c4b6c4804f0520c43a705fd13eb627445bcd80bff8bfa25e09ecd178",
          "size": 562
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:102a747c137683e81d431dab05d8f2158df4ab6f162f8f9019425a43d51e0e9f",
            "size": 14333908384
          },
          {
            "mediaType": "Template",
            "digest": "sha256:6db27cd4e277c91264572b9c899c1980daa8dea11e902f0070a6f4763f3d13c8",
            "size": 695
          },
          {
            "mediaType": "application/vnd.ollama.image.system",
            "digest": "sha256:6d7b25ffd24789fb9fb5c5ba702a4ae77fa8ba27ecf868442278611161511fc6",
            "size": 644
          },
          {
            "mediaType": "License",
            "digest": "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "size": 11356
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:e0daf17ff83eace4813f9e8554b262f6cc33ad880ff8df41a156ff9ef5522ddb",
            "size": 21
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "23.6B",
        "file_type": "Q4_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:102a747c137683e81d431dab05d8f2158df4ab6f162f8f9019425a43d51e0e9f",
            "sha256:6db27cd4e277c91264572b9c899c1980daa8dea11e902f0070a6f4763f3d13c8",
            "sha256:6d7b25ffd24789fb9fb5c5ba702a4ae77fa8ba27ecf868442278611161511fc6",
            "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "sha256:e0daf17ff83eace4813f9e8554b262f6cc33ad880ff8df41a156ff9ef5522ddb"
          ]
        }
      },
      "context_length": null,
      "model_type": "23.6B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q2_K",
      "last_updated": "10 months ago",
      "size": "8.3GB",
      "digest": "sha256:c5bc8632d68ed2a123fe90917a8a1e5999fba12e41b51fd6c8bc3cf905ae5c13",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:c5bc8632d68ed2a123fe90917a8a1e5999fba12e41b51fd6c8bc3cf905ae5c13",
          "size": 486
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:7cff049e08a773db8400faecedd390588162a19a842b067cafe752bc81d55c55",
            "size": 8272095104
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q2_K",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:7cff049e08a773db8400faecedd390588162a19a842b067cafe752bc81d55c55",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q3_K_S",
      "last_updated": "10 months ago",
      "size": "9.6GB",
      "digest": "sha256:0fe276b083beb63dbdf9aad81a6b7279bb7ea3c59696e5c7eb3bd559791915dd",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:0fe276b083beb63dbdf9aad81a6b7279bb7ea3c59696e5c7eb3bd559791915dd",
          "size": 488
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:1170527fab5b8db184a1d14a7978d5e29bd6ec08cd041d2472c4af6fcb1591ee",
            "size": 9641273216
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q3_K_S",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:1170527fab5b8db184a1d14a7978d5e29bd6ec08cd041d2472c4af6fcb1591ee",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q3_K_M",
      "last_updated": "10 months ago",
      "size": "11GB",
      "digest": "sha256:d8206e5db86fe0f7a8bd849c00aa5850c7bff097ae5690892b00ec9319c73cc4",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:d8206e5db86fe0f7a8bd849c00aa5850c7bff097ae5690892b00ec9319c73cc4",
          "size": 488
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:2abed89b211bde4c5b31243a684bd0296cc8dcf32ef82045b7b888a1f0c60051",
            "size": 10756827008
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q3_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:2abed89b211bde4c5b31243a684bd0296cc8dcf32ef82045b7b888a1f0c60051",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q3_K_L",
      "last_updated": "10 months ago",
      "size": "12GB",
      "digest": "sha256:019064460d06046079980558865d39ebfc443b9b0384381280468da41b11d540",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:019064460d06046079980558865d39ebfc443b9b0384381280468da41b11d540",
          "size": 488
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:b22b99a83c5823f77182fa6e0f06d0143648a18e1405ba216772b1a22bbc4ba0",
            "size": 11730429824
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q3_K_L",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:b22b99a83c5823f77182fa6e0f06d0143648a18e1405ba216772b1a22bbc4ba0",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q4_0",
      "last_updated": "10 months ago",
      "size": "13GB",
      "digest": "sha256:183659ffa02e4a94ef89f0a040bb9f5363dfadbdb2433395701feeb1df362595",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:183659ffa02e4a94ef89f0a040bb9f5363dfadbdb2433395701feeb1df362595",
          "size": 486
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:e5f39205cb1323dbfce381f15993d66ec7b40374b2cc1961bdf62828fb9709d1",
            "size": 12569159552
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q4_0",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:e5f39205cb1323dbfce381f15993d66ec7b40374b2cc1961bdf62828fb9709d1",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q4_1",
      "last_updated": "10 months ago",
      "size": "14GB",
      "digest": "sha256:0164f0a8d711d2f4990dcbd395dae7f7ebeb9d8f5973c3160f3ed31e49d60553",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:0164f0a8d711d2f4990dcbd395dae7f7ebeb9d8f5973c3160f3ed31e49d60553",
          "size": 486
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:c68b9986c5816e27779f0d1ee46708a4c709345beabf75fe450dc43d53d1babc",
            "size": 13946988416
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q4_1",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:c68b9986c5816e27779f0d1ee46708a4c709345beabf75fe450dc43d53d1babc",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q4_K_S",
      "last_updated": "10 months ago",
      "size": "13GB",
      "digest": "sha256:3bb73eb50afbfb506b7b731db553d5b04645d855fef43ab2b65eecc4ec916814",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:3bb73eb50afbfb506b7b731db553d5b04645d855fef43ab2b65eecc4ec916814",
          "size": 488
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:10decc7499efd7f62f06b3598cd2732c00575ee257d9bf4558c86b2b16ca26ae",
            "size": 12660385664
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q4_K_S",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:10decc7499efd7f62f06b3598cd2732c00575ee257d9bf4558c86b2b16ca26ae",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q4_K_M",
      "last_updated": "10 months ago",
      "size": "13GB",
      "digest": "sha256:bec83159fda801aa4c6355c1d309287235400daa1cc5499cb01eaff4245b1765",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:bec83159fda801aa4c6355c1d309287235400daa1cc5499cb01eaff4245b1765",
          "size": 488
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:7f39b4b7da055cab91127a7297aa4e6490999e1443d6be679b303555c64c1c5d",
            "size": 13341239168
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q4_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:7f39b4b7da055cab91127a7297aa4e6490999e1443d6be679b303555c64c1c5d",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q5_0",
      "last_updated": "10 months ago",
      "size": "15GB",
      "digest": "sha256:80e156a205ea2ba4d1ad44198dd0e69b025398111ee21424c1de5713b47a56b5",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:80e156a205ea2ba4d1ad44198dd0e69b025398111ee21424c1de5713b47a56b5",
          "size": 486
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:512df9fdacac40e3dee91a0a50505ff27ccb48ddbfa01647147a2cadc4912b01",
            "size": 15324817280
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q5_0",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:512df9fdacac40e3dee91a0a50505ff27ccb48ddbfa01647147a2cadc4912b01",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q5_1",
      "last_updated": "10 months ago",
      "size": "17GB",
      "digest": "sha256:65a57ef4820d2fd392b4079e154fd5015ea0c85124efb42b14dc4be006ad66b1",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:65a57ef4820d2fd392b4079e154fd5015ea0c85124efb42b14dc4be006ad66b1",
          "size": 486
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:751e848b328a7b19cabdbea6df2678f66048e20d3dd51e8abafb0e817fa298e5",
            "size": 16702646144
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q5_1",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:751e848b328a7b19cabdbea6df2678f66048e20d3dd51e8abafb0e817fa298e5",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q5_K_S",
      "last_updated": "10 months ago",
      "size": "15GB",
      "digest": "sha256:4905f030559fd7dff31e7941999924a5baa36ba11c78e2a612ef7945e7b2e583",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:4905f030559fd7dff31e7941999924a5baa36ba11c78e2a612ef7945e7b2e583",
          "size": 488
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:fdedbe1e0d23f06b43c2128ba64db76205b9231f8aef7425e7a7bec1bd8ba622",
            "size": 15324817280
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q5_K_S",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:fdedbe1e0d23f06b43c2128ba64db76205b9231f8aef7425e7a7bec1bd8ba622",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q5_K_M",
      "last_updated": "10 months ago",
      "size": "16GB",
      "digest": "sha256:43868be1dbaaca6b874b1434a1805044180319947861fd499195562417e253f0",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:43868be1dbaaca6b874b1434a1805044180319947861fd499195562417e253f0",
          "size": 488
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:5e8e0326a24c7a58f481f16be103dce9316c32e0070ed342d75ddeb7ed5c14de",
            "size": 15722555264
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q5_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:5e8e0326a24c7a58f481f16be103dce9316c32e0070ed342d75ddeb7ed5c14de",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q6_K",
      "last_updated": "10 months ago",
      "size": "18GB",
      "digest": "sha256:6f87ecf6304bdc7db5762e8bc0ef884393505d41671b81c52905304be7139d4f",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:6f87ecf6304bdc7db5762e8bc0ef884393505d41671b81c52905304be7139d4f",
          "size": 486
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:dd2ec46a624211c9fceb7dc454a6f576986ba490015bbabed857c8af224f6646",
            "size": 18252703616
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q6_K",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:dd2ec46a624211c9fceb7dc454a6f576986ba490015bbabed857c8af224f6646",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-q8_0",
      "last_updated": "10 months ago",
      "size": "24GB",
      "digest": "sha256:7604d114227b3a07f68be2b417986468198aa768c6076ea90e29f96ca1e9ecfa",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:7604d114227b3a07f68be2b417986468198aa768c6076ea90e29f96ca1e9ecfa",
          "size": 486
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:97b488b7670c40d50162a33163b3b86fecc19c7bfe787fad0cc617821ed99a59",
            "size": 23640549248
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "Q8_0",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:97b488b7670c40d50162a33163b3b86fecc19c7bfe787fad0cc617821ed99a59",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:22b-instruct-2409-fp16",
      "last_updated": "10 months ago",
      "size": "44GB",
      "digest": "sha256:72592081de0129b6c2602446a4a089357165fe0e279911113790a11c09876050",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:72592081de0129b6c2602446a4a089357165fe0e279911113790a11c09876050",
          "size": 485
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:a549146de82d9544c7db0b6255a0164fc0bca7179686526eacee5d22445b3376",
            "size": 44496725888,
            "from": "/Users/ollama/.ollama/models/blobs/sha256-a549146de82d9544c7db0b6255a0164fc0bca7179686526eacee5d22445b3376"
          },
          {
            "mediaType": "Template",
            "digest": "sha256:cfee52e2391b9ea027565825628a5e8aa00815553b56df90ebc844a9bc15b1c8",
            "size": 900
          },
          {
            "mediaType": "License",
            "digest": "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "size": 11156
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da",
            "size": 47
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "22.2B",
        "file_type": "F16",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:a549146de82d9544c7db0b6255a0164fc0bca7179686526eacee5d22445b3376",
            "sha256:0aba190b6ff112a16804af34df461379dea3a1887c42234235757561fa6ae06a",
            "sha256:06a6f77f3e9529e5c8826794c2057c2270968fae4c5cb99432d00671082e6ba8",
            "sha256:ac9aa3c4956dba22deb5330f3dfc21a403d74742ef7227033235a92a3808e4da"
          ]
        }
      },
      "context_length": null,
      "model_type": "22.2B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:24b-instruct-2501-q4_K_M",
      "last_updated": "5 months ago",
      "size": "14GB",
      "digest": "sha256:41ffc852c4b6c4804f0520c43a705fd13eb627445bcd80bff8bfa25e09ecd178",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:41ffc852c4b6c4804f0520c43a705fd13eb627445bcd80bff8bfa25e09ecd178",
          "size": 562
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:102a747c137683e81d431dab05d8f2158df4ab6f162f8f9019425a43d51e0e9f",
            "size": 14333908384
          },
          {
            "mediaType": "Template",
            "digest": "sha256:6db27cd4e277c91264572b9c899c1980daa8dea11e902f0070a6f4763f3d13c8",
            "size": 695
          },
          {
            "mediaType": "application/vnd.ollama.image.system",
            "digest": "sha256:6d7b25ffd24789fb9fb5c5ba702a4ae77fa8ba27ecf868442278611161511fc6",
            "size": 644
          },
          {
            "mediaType": "License",
            "digest": "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "size": 11356
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:e0daf17ff83eace4813f9e8554b262f6cc33ad880ff8df41a156ff9ef5522ddb",
            "size": 21
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "23.6B",
        "file_type": "Q4_K_M",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:102a747c137683e81d431dab05d8f2158df4ab6f162f8f9019425a43d51e0e9f",
            "sha256:6db27cd4e277c91264572b9c899c1980daa8dea11e902f0070a6f4763f3d13c8",
            "sha256:6d7b25ffd24789fb9fb5c5ba702a4ae77fa8ba27ecf868442278611161511fc6",
            "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "sha256:e0daf17ff83eace4813f9e8554b262f6cc33ad880ff8df41a156ff9ef5522ddb"
          ]
        }
      },
      "context_length": null,
      "model_type": "23.6B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:24b-instruct-2501-q8_0",
      "last_updated": "5 months ago",
      "size": "25GB",
      "digest": "sha256:6cdcd0af8773bec76a5b1cef0067af5e2175f924677656e564bb0de63fb7aee0",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:6cdcd0af8773bec76a5b1cef0067af5e2175f924677656e564bb0de63fb7aee0",
          "size": 560
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:a58ad27c3b12c567ca6a60806696a7689f9cf929f2a56aa7189c5908e60e7222",
            "size": 25054778784
          },
          {
            "mediaType": "Template",
            "digest": "sha256:6db27cd4e277c91264572b9c899c1980daa8dea11e902f0070a6f4763f3d13c8",
            "size": 695
          },
          {
            "mediaType": "application/vnd.ollama.image.system",
            "digest": "sha256:6d7b25ffd24789fb9fb5c5ba702a4ae77fa8ba27ecf868442278611161511fc6",
            "size": 644
          },
          {
            "mediaType": "License",
            "digest": "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "size": 11356
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:e0daf17ff83eace4813f9e8554b262f6cc33ad880ff8df41a156ff9ef5522ddb",
            "size": 21
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "23.6B",
        "file_type": "Q8_0",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:a58ad27c3b12c567ca6a60806696a7689f9cf929f2a56aa7189c5908e60e7222",
            "sha256:6db27cd4e277c91264572b9c899c1980daa8dea11e902f0070a6f4763f3d13c8",
            "sha256:6d7b25ffd24789fb9fb5c5ba702a4ae77fa8ba27ecf868442278611161511fc6",
            "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "sha256:e0daf17ff83eace4813f9e8554b262f6cc33ad880ff8df41a156ff9ef5522ddb"
          ]
        }
      },
      "context_length": null,
      "model_type": "23.6B",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "mistral-small:24b-instruct-2501-fp16",
      "last_updated": "5 months ago",
      "size": "47GB",
      "digest": "sha256:2f76f7f1f490139a5a372dd736af7266df6a2a096930ff95d4727aa3d70ba406",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:2f76f7f1f490139a5a372dd736af7266df6a2a096930ff95d4727aa3d70ba406",
          "size": 559
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:7d022d344fc6d21fb8d15c5cf48b0d0b2ec7d7bd90f0489c6b90fdae6e506255",
            "size": 47153517984,
            "from": "/Users/administrator/.ollama/models/blobs/sha256-7d022d344fc6d21fb8d15c5cf48b0d0b2ec7d7bd90f0489c6b90fdae6e506255"
          },
          {
            "mediaType": "Template",
            "digest": "sha256:6db27cd4e277c91264572b9c899c1980daa8dea11e902f0070a6f4763f3d13c8",
            "size": 695
          },
          {
            "mediaType": "application/vnd.ollama.image.system",
            "digest": "sha256:6d7b25ffd24789fb9fb5c5ba702a4ae77fa8ba27ecf868442278611161511fc6",
            "size": 644
          },
          {
            "mediaType": "License",
            "digest": "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "size": 11356
          },
          {
            "mediaType": "Parameters",
            "digest": "sha256:e0daf17ff83eace4813f9e8554b262f6cc33ad880ff8df41a156ff9ef5522ddb",
            "size": 21
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "llama",
        "model_families": [
          "llama"
        ],
        "model_type": "23.6B",
        "file_type": "F16",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:7d022d344fc6d21fb8d15c5cf48b0d0b2ec7d7bd90f0489c6b90fdae6e506255",
            "sha256:6db27cd4e277c91264572b9c899c1980daa8dea11e902f0070a6f4763f3d13c8",
            "sha256:6d7b25ffd24789fb9fb5c5ba702a4ae77fa8ba27ecf868442278611161511fc6",
            "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
            "sha256:e0daf17ff83eace4813f9e8554b262f6cc33ad880ff8df41a156ff9ef5522ddb"
          ]
        }
      },
      "context_length": null,
      "model_type": "23.6B",
      "quantization": null,
      "base_model": null
    }
  ],
  "annotations": {
    "ollama.input_type": "code"
  },
  "quality_score": {
    "fields_filled": 27,
    "total_possible": 51,
    "completeness": 0.53
  }
}