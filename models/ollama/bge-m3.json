{
  "name": "bge-m3",
  "description": "BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-Functionality, Multi-Linguality, and Multi-Granularity.",
  "pull_count": 1600000,
  "last_updated": "Aug 7, 2024 12:07 AM UTC",
  "readme_html": "<div class=\"prose-td code:display-inline-block prose-td code:bg-gray-200 prose-td code:px-2 prose-td code:py-1 prose-td code:rounded-md prose prose-headings:mb-[0.7em] prose-headings:mt-[1.25em] prose-headings:font-semibold prose-headings:tracking-tight prose-h1:text-[32px] prose-h2:text-2xl prose-h3:text-xl prose-h4:text-lg prose-h5:text-base prose-p:mb-4 prose-p:mt-0 prose-p:leading-relaxed prose-p:before:hidden prose-p:after:hidden prose-blockquote:font-normal prose-blockquote:not-italic prose-blockquote:text-neutral-500 prose-blockquote:before:hidden prose-blockquote:after:hidden prose-code:my-0 prose-code:inline-block prose-code:rounded-md prose-code:bg-neutral-100 prose-code:px-2 prose-code:text-[85%] prose-code:font-normal prose-code:leading-relaxed prose-code:text-black prose-code:before:hidden prose-code:after:hidden prose-pre:mb-4 prose-pre:mt-0 prose-pre:whitespace-pre-wrap prose-pre:rounded-lg prose-pre:bg-neutral-100 prose-pre:px-3 prose-pre:py-3 prose-pre:text-base prose-pre:text-black prose-ol:mb-4 prose-ol:mt-1 prose-ol:pl-8 marker:prose-ol:text-black prose-ul:mb-4 prose-ul:mt-1 prose-ul:pl-8 marker:prose-ul:text-black prose-li:mb-0 prose-li:mt-0.5 prose-li:text-black first:prose-li:mt-0 prose-table:w-full prose-table:table-auto prose-table:border-collapse prose-th:break-words prose-th:text-center prose-th:font-semibold prose-td:break-words prose-td:px-4 prose-td:py-2 prose-td:text-left prose-img:mx-auto prose-img:my-12 prose-video:my-12 max-w-none overflow-auto py-5 text-black\" id=\"display\">\n<p>BGE-M3 is based on the XLM-RoBERTa architecture and is distinguished for its versatility in Multi-Functionality, Multi-Linguality, and Multi-Granularity:</p>\n<ul>\n<li>Multi-Functionality: It can simultaneously perform the three common retrieval functionalities of embedding model: dense retrieval, multi-vector retrieval, and sparse retrieval.</li>\n<li>Multi-Linguality: It can support more than 100 working languages.</li>\n<li>Multi-Granularity: It is able to process inputs of different granularities, spanning from short sentences to long documents of up to 8192 tokens.</li>\n</ul>\n<p><strong>Benchmarks from the open-source community</strong>\n<img alt=\"image.png\" src=\"https://ollama.com/assets/library/bge-m3/17a9804b-f3da-4d09-bd18-90d4fe8900d3\"/></p>\n<pre><code>@misc{bge-m3,\n      title={BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation}, \n      author={Jianlv Chen and Shitao Xiao and Peitian Zhang and Kun Luo and Defu Lian and Zheng Liu},\n      year={2024},\n      eprint={2402.03216},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n</code></pre>\n</div>",
  "page_hash": "d105062a9a3e",
  "readme_text": "\nBGE-M3 is based on the XLM-RoBERTa architecture and is distinguished for its versatility in Multi-Functionality, Multi-Linguality, and Multi-Granularity:\n\nMulti-Functionality: It can simultaneously perform the three common retrieval functionalities of embedding model: dense retrieval, multi-vector retrieval, and sparse retrieval.\nMulti-Linguality: It can support more than 100 working languages.\nMulti-Granularity: It is able to process inputs of different granularities, spanning from short sentences to long documents of up to 8192 tokens.\n\nBenchmarks from the open-source community\n\n@misc{bge-m3,\n      title={BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation}, \n      author={Jianlv Chen and Shitao Xiao and Peitian Zhang and Kun Luo and Defu Lian and Zheng Liu},\n      year={2024},\n      eprint={2402.03216},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n",
  "tags": [
    {
      "tag": "bge-m3:latest",
      "last_updated": "11 months ago",
      "size": "1.2GB",
      "digest": "sha256:0c4c9c2a325fb1cdafec606e6809cb745f1cb26a6d919994400d27372303e276",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:0c4c9c2a325fb1cdafec606e6809cb745f1cb26a6d919994400d27372303e276",
          "size": 337
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:daec91ffb5dd0c27411bd71f29932917c49cf529a641d0168496c3a501e3062c",
            "size": 1157671200
          },
          {
            "mediaType": "License",
            "digest": "sha256:a406579cd136771c705c521db86ca7d60a6f3de7c9b5460e6193a2df27861bde",
            "size": 1068
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "bert",
        "model_families": [
          "bert"
        ],
        "model_type": "566.70M",
        "file_type": "F16",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:daec91ffb5dd0c27411bd71f29932917c49cf529a641d0168496c3a501e3062c",
            "sha256:a406579cd136771c705c521db86ca7d60a6f3de7c9b5460e6193a2df27861bde"
          ]
        }
      },
      "context_length": null,
      "model_type": "566.70M",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "bge-m3:567m",
      "last_updated": "11 months ago",
      "size": "1.2GB",
      "digest": "sha256:0c4c9c2a325fb1cdafec606e6809cb745f1cb26a6d919994400d27372303e276",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:0c4c9c2a325fb1cdafec606e6809cb745f1cb26a6d919994400d27372303e276",
          "size": 337
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:daec91ffb5dd0c27411bd71f29932917c49cf529a641d0168496c3a501e3062c",
            "size": 1157671200
          },
          {
            "mediaType": "License",
            "digest": "sha256:a406579cd136771c705c521db86ca7d60a6f3de7c9b5460e6193a2df27861bde",
            "size": 1068
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "bert",
        "model_families": [
          "bert"
        ],
        "model_type": "566.70M",
        "file_type": "F16",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:daec91ffb5dd0c27411bd71f29932917c49cf529a641d0168496c3a501e3062c",
            "sha256:a406579cd136771c705c521db86ca7d60a6f3de7c9b5460e6193a2df27861bde"
          ]
        }
      },
      "context_length": null,
      "model_type": "566.70M",
      "quantization": null,
      "base_model": null
    },
    {
      "tag": "bge-m3:567m-fp16",
      "last_updated": "11 months ago",
      "size": "1.2GB",
      "digest": "sha256:0c4c9c2a325fb1cdafec606e6809cb745f1cb26a6d919994400d27372303e276",
      "manifest": {
        "schemaVersion": 2,
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "config": {
          "mediaType": "application/vnd.docker.container.image.v1+json",
          "digest": "sha256:0c4c9c2a325fb1cdafec606e6809cb745f1cb26a6d919994400d27372303e276",
          "size": 337
        },
        "layers": [
          {
            "mediaType": "Model Weights",
            "digest": "sha256:daec91ffb5dd0c27411bd71f29932917c49cf529a641d0168496c3a501e3062c",
            "size": 1157671200
          },
          {
            "mediaType": "License",
            "digest": "sha256:a406579cd136771c705c521db86ca7d60a6f3de7c9b5460e6193a2df27861bde",
            "size": 1068
          }
        ]
      },
      "config": {
        "model_format": "gguf",
        "model_family": "bert",
        "model_families": [
          "bert"
        ],
        "model_type": "566.70M",
        "file_type": "F16",
        "architecture": "amd64",
        "os": "linux",
        "rootfs": {
          "type": "layers",
          "diff_ids": [
            "sha256:daec91ffb5dd0c27411bd71f29932917c49cf529a641d0168496c3a501e3062c",
            "sha256:a406579cd136771c705c521db86ca7d60a6f3de7c9b5460e6193a2df27861bde"
          ]
        }
      },
      "context_length": null,
      "model_type": "566.70M",
      "quantization": null,
      "base_model": null
    }
  ],
  "annotations": {
    "ollama.input_type": "text"
  },
  "quality_score": {
    "fields_filled": 9,
    "total_possible": 15,
    "completeness": 0.6
  }
}