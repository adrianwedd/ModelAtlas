{
  "name": "mistral-nemo",
  "description": "A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.",
  "pull_count": 2100000,
  "last_updated": "Aug 5, 2024 10:14 PM UTC",
  "page_hash": "a9bca4c8b34a",
  "tags": [
    {
      "name": "application/vnd.ollama.image.model",
      "digest": "sha256:b559938ab7a0392fc9ea9675b82280f2a15669ec3e0e0fc491c9cb0a7681cf94",
      "size": "6.59GB",
      "media_type": "application/vnd.ollama.image.model",
      "annotations": {}
    },
    {
      "name": "application/vnd.ollama.image.template",
      "digest": "sha256:f023d1ce0e55d0dcdeaf70ad81555c2a20822ed607a7abd8de3c3131360f5f0a",
      "size": "0.0GB",
      "media_type": "application/vnd.ollama.image.template",
      "annotations": {}
    },
    {
      "name": "application/vnd.ollama.image.license",
      "digest": "sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1",
      "size": "0.0GB",
      "media_type": "application/vnd.ollama.image.license",
      "annotations": {}
    },
    {
      "name": "application/vnd.ollama.image.params",
      "digest": "sha256:ed11eda7790d05b49395598a42b155812b17e263214292f7b87d15e14003d337",
      "size": "0.0GB",
      "media_type": "application/vnd.ollama.image.params",
      "annotations": {}
    }
  ]
}